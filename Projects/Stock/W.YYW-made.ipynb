{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total : 3605  Available : 295  percentage : 8.183079056865465 %\n"
     ]
    }
   ],
   "source": [
    "#먼저 이걸 돌려야 함. 길이 N >=1000 인 데이터만 모았음, 상장폐지 꺼졍\n",
    "#google용으로 만들 때는 아래 gpath 주석 제거.\n",
    "import pandas as pd\n",
    "import glob\n",
    "today_date='2020.04.29'\n",
    "path1='C:/Users/mod96/Desktop/HSH/StudyingMaterials/Project - datascience/dataset'\n",
    "#gpath='C:/Users/mod96/Desktop/HSH/StudyingMaterials/Project - datascience/dataset/'\n",
    "gpath='/content/gdrive/Shared drives/STOCK/version1/dataset/'\n",
    "available_path='C:/Users/mod96/Desktop/HSH/StudyingMaterials/Project - datascience/available/available.csv'\n",
    "#############################삼성만큼 길이=5996 이지만 hard coding 을 피해보자.\n",
    "f=pd.read_csv(open( path1+'/005930.csv' ))\n",
    "N=f.shape[0]\n",
    "#############################\n",
    "files=glob.glob(path1+'/*.csv')\n",
    "available=[]\n",
    "for file in files:\n",
    "    f=pd.read_csv(open(file.replace('\\\\', '/')))\n",
    "    if f.shape[0]>=N:\n",
    "        if f.loc[0,'날짜']==today_date:\n",
    "            available.append(gpath+file.replace('\\\\', '/')[-10:-4]+'.csv')\n",
    "print('Total :',len(files),' Available :',len(available),' percentage :',100*len(available)/len(files),'%')\n",
    "av=pd.Series(available)\n",
    "av.to_csv(available_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum length : 5996   maximum length indexs 295\n"
     ]
    }
   ],
   "source": [
    "######################################어느정도까지 잘라야 하나 보자.\n",
    "available=list(pd.read_csv(open('C:/Users/mod96/Desktop/HSH/StudyingMaterials/Project - datascience/available/available.csv')).iloc[:,1])\n",
    "lengths={}\n",
    "for file in available:\n",
    "    f=pd.read_csv(open(file))\n",
    "    temp=f.shape[0]\n",
    "    lengths.setdefault(temp,[]).append(file)\n",
    "M=max(lengths.keys())\n",
    "print(\"maximum length :\",M,\"  maximum length indexs\",len(lengths[M]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.모델 러닝\n",
    "========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing with index 000180\n",
      "Data Length : 5996\n",
      "Train on 5350 samples\n",
      "Epoch 1/20\n",
      "  10/5350 [..............................] - ETA: 13:33"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:168: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-21-8948334d146a>\", line 132, in <module>\n",
      "    history=model.fit(x_train,y_train,epochs=20,batch_size=10,verbose=1)   #여기에서 시간이 오래걸림\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 819, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 342, in fit\n",
      "    total_epochs=epochs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 128, in run_one_epoch\n",
      "    batch_outs = execution_function(iterator)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\", line 98, in execution_function\n",
      "    distributed_function(input_fn))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 568, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 632, in _call\n",
      "    return self._stateless_fn(*args, **kwds)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 2362, in __call__\n",
      "    graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 2703, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 2593, in _create_graph_function\n",
      "    capture_by_value=self._capture_by_value),\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\", line 978, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 439, in wrapped_fn\n",
      "    return weak_wrapped_fn().__wrapped__(*args, **kwds)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\", line 85, in distributed_function\n",
      "    per_replica_function, args=args)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\", line 763, in experimental_run_v2\n",
      "    return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\", line 1819, in call_for_each_replica\n",
      "    return self._call_for_each_replica(fn, args, kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\", line 2164, in _call_for_each_replica\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\api.py\", line 292, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\", line 433, in train_on_batch\n",
      "    output_loss_metrics=model._output_loss_metrics)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\", line 312, in train_on_batch\n",
      "    output_loss_metrics=output_loss_metrics))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\", line 269, in _process_single_batch\n",
      "    grads = tape.gradient(scaled_total_loss, trainable_weights)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\backprop.py\", line 1029, in gradient\n",
      "    unconnected_gradients=unconnected_gradients)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\imperative_grad.py\", line 77, in imperative_grad\n",
      "    compat.as_str(unconnected_gradients.value))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 788, in _backward_function\n",
      "    return self._rewrite_forward_and_call_backward(call_op, *args)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 707, in _rewrite_forward_and_call_backward\n",
      "    forward_function, backwards_function = self.forward_backward(len(doutputs))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 616, in forward_backward\n",
      "    forward, backward = self._construct_forward_backward(num_doutputs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 702, in _construct_forward_backward\n",
      "    self._func_graph.outputs, forward_function_attr)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 451, in __init__\n",
      "    compat.as_str(\"\"))\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-21-8948334d146a>\", line 173, in <module>\n",
      "    sys.exit(0)\n",
      "SystemExit: 0\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1151, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "AttributeError: 'tuple' object has no attribute 'tb_frame'\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#모든 주식에 대해 돌려야 하는 코드\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "########################################################################################\n",
    "path='C:/Users/mod96/Desktop/HSH/StudyingMaterials/Project - datascience/dataset/'\n",
    "save_path='C:/Users/mod96/Desktop/HSH/StudyingMaterials/Project - datascience/models/'\n",
    "trustval_path='C:/Users/mod96/Desktop/HSH/StudyingMaterials/Project - datascience/trustvalue/'\n",
    "available_path='C:/Users/mod96/Desktop/HSH/StudyingMaterials/Project - datascience/available/available.csv'\n",
    "seq_length=50\n",
    "TARGET=2  #0: 종가 1: 시가 2: 고가 3: 저가\n",
    "########################################################################################\n",
    "def datapreparation(KEY_path):\n",
    "    data=pd.read_csv(open(KEY_path))\n",
    "    if int(data.loc[0,'거래량'])==0:          #FaceDivision 처리할 때 index out of range 를 방지하기 위함.\n",
    "        data.loc[0,'거래량']=1\n",
    "    if int(data.loc[data.shape[0]-1,'거래량'])==0:\n",
    "        data.loc[data.shape[0]-1,'거래량']=1\n",
    "    data.drop(['Unnamed: 0','전일비','날짜'],axis=1,inplace=True)\n",
    "    data=data.reindex(index=data.index[::-1])\n",
    "\n",
    "    return data\n",
    "\n",
    "def FaceDivision(df):\n",
    "    if np.isnan(df.to_numpy()).any():\n",
    "        print(\"there exist NaN in raw data\")\n",
    "        print(df[df==np.nan])\n",
    "        raise NotImplementedError\n",
    "    if df.loc[0,'시가']==0:            #거래정지처리\n",
    "        df.loc[0,'시가']=df.loc[0,'종가']\n",
    "    temp1=pd.DataFrame(df.to_numpy(),columns=df.columns)\n",
    "    temp2=temp1.drop('거래량',axis=1)\n",
    "    index1=list(temp1[temp1['거래량']==0].index) \n",
    "    #비인기주는 아무도 관심을 주지 않아(...) 거래량이 0인 경우도 있다.\n",
    "    #또한 액면분할은 여러번 있을 수 있다.\n",
    "    \n",
    "    idx=[]\n",
    "    for i in range(len(index1)-1):\n",
    "        if index1[i+1]-index1[i]>1:\n",
    "            idx.append(int(i))\n",
    "    idx.insert(0,-1)\n",
    "    DivisionDays=[]\n",
    "    for i in range(len(idx)-1):\n",
    "        DivisionDays.append(index1[idx[i]+1:idx[i+1]+1])\n",
    "    DivisionDays.append(index1[idx[-1]+1:])\n",
    "    if len(DivisionDays[0])>0:\n",
    "        for i in range(len(DivisionDays)):\n",
    "            beforeDivision=temp2.loc[DivisionDays[i][0]-1,'종가']\n",
    "            afterDivision=temp2.loc[DivisionDays[i][-1]+1,'시가']\n",
    "            ratio=afterDivision/beforeDivision\n",
    "            if 1/ratio>=1.5:                       #after 에 비해 before 가 1.5 배 이상이면 액면분할이라 가정\n",
    "                temp2.loc[:DivisionDays[i][-1]]=temp2.loc[:DivisionDays[i][-1]]*ratio   #df의 slicing 은 거기까지 포함한다.\n",
    "    \n",
    "    return temp2\n",
    "\n",
    "def Emptyfill(df):            #종가가 모두 존재한다는 가정 하에 시가/고가/저가 항목이 비어있으면 채워준다.\n",
    "    temp=np.array(df.loc[:,'종가'])\n",
    "    temp=np.where(temp==0,np.nan,temp)\n",
    "    assert ~np.isnan(temp).any(), \"there exist 0 in '종가' column\"\n",
    "    \n",
    "    for item in ['시가','고가','저가']:\n",
    "        index1=list(df[df[item].map(int)==0].index)\n",
    "        for each in index1:\n",
    "            df.loc[each,item]=df.loc[each,'종가']\n",
    "    \n",
    "    return df\n",
    "\n",
    "def df2nps(df,seqlen):\n",
    "    seq_len=seqlen+1\n",
    "    temp=df.to_numpy()\n",
    "    result=[]\n",
    "    for i in range(df.shape[0]-seq_len):\n",
    "        result.append( temp[i:i+seq_len,:] )\n",
    "        \n",
    "    return np.array(result)\n",
    "\n",
    "def normalization_and_split(result,train_ratio,TARGET):\n",
    "    denoms=[]\n",
    "    for table in result:\n",
    "        temp=[]\n",
    "        for i in range(table.shape[1]):\n",
    "            denominator=float(table[0,i])\n",
    "            table[:,i]=(table[:,i]/denominator)-1\n",
    "            temp.append(denominator)\n",
    "        denoms.append(temp)\n",
    "    denoms=np.array(denoms)\n",
    "\n",
    "    #sklearn 에서 자동으로 섞어주는게 있는데 그것보단 순서 고려해서 쪼개는게 좋은듯\n",
    "    ratio=int(round(len(result)*train_ratio))\n",
    "    train=result[:ratio,:,:]\n",
    "    np.random.shuffle(train)\n",
    "    x_train=train[:,:-1,:]\n",
    "    y_train=train[:,-1,TARGET]\n",
    "    \n",
    "    x_test=result[ratio:,:-1,:]\n",
    "    y_test=result[ratio:,-1,TARGET]\n",
    "    denoms=denoms[ratio:,TARGET]\n",
    "\n",
    "    return x_train, y_train, x_test, y_test, denoms\n",
    "\n",
    "def trustValue(model,history,x_test,y_test,denoms):\n",
    "    pred = model.predict(x_test)\n",
    "    Ytest=(y_test+1)*denoms\n",
    "    Ypred=(pred.reshape(pred.shape[0])+1)*denoms\n",
    "    Ytest_pct=pd.Series(Ytest).pct_change().dropna()\n",
    "    Ypred_pct=pd.Series(Ypred).pct_change().dropna()\n",
    "    CORR=np.corrcoef(Ytest_pct.values,Ypred_pct.values)\n",
    "\n",
    "    return CORR[0,1]\n",
    "########################################################################################\n",
    "KEY_paths=pd.read_csv(open(available_path)).drop('Unnamed: 0',axis=1)\n",
    "avail=list(KEY_paths.values.reshape((KEY_paths.shape[0])))\n",
    "fail=[]\n",
    "for KEY_path in KEY_paths.values:\n",
    "    try:\n",
    "        print(\"Processing with index\",KEY_path[0][-10:-4])\n",
    "        avail.remove(KEY_path[0])\n",
    "        data=datapreparation(KEY_path[0])\n",
    "        data= FaceDivision(data)\n",
    "        data=Emptyfill(data)\n",
    "        print(\"Data Length :\",data.shape[0])\n",
    "        result=df2nps( data, seq_length )\n",
    "        x_train, y_train, x_test, y_test, denoms = normalization_and_split(result,0.9,TARGET)\n",
    "\n",
    "        model=Sequential()  #LSTM, adam 이 그나마 나음.\n",
    "        model.add( layers.LSTM(50, return_sequences=True,input_shape=(50,4)) )\n",
    "        model.add( layers.LSTM(64, return_sequences=False))\n",
    "        model.add( layers.Dense(1, activation='linear'))\n",
    "        model.compile(loss='MSE',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "        history=model.fit(x_train,y_train,epochs=10,batch_size=10,verbose=1)   #여기에서 시간이 오래걸림\n",
    "        if history.history[ 'loss' ][-1]<0.001:\n",
    "            model.fit(x_train,y_train,epochs=10,batch_size=10,verbose=1)\n",
    "            model.save(save_path+KEY_path[0][-10:-4]+'.h5')\n",
    "            T=trustValue(model,x_test,y_test,denoms)\n",
    "            print(\"Correlation Coefficient :\",T)\n",
    "            f = open(trustval_path+KEY_path[0][-10:-4]+'.txt', \"w\")\n",
    "            f.write(str(T))\n",
    "            f.close()\n",
    "        else:\n",
    "            print('loss is not converging. pass')\n",
    "    except KeyboardInterrupt:\n",
    "        avail.insert(0,KEY_path[0])\n",
    "        av=pd.Series(avail)\n",
    "        av.to_csv(available_path)\n",
    "        ff=pd.Series(fail)\n",
    "        ff.to_csv(available_path[:-13]+'ErrorLog.csv')\n",
    "        import sys \n",
    "        sys.exit(0)\n",
    "    except:\n",
    "        print('TypeError')\n",
    "        fail.append(KEY_path[0])\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.모델로 다음날 예측\n",
    "======="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델을 불러오고 다음 값을 얻어내는 코드\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "########################################################################################\n",
    "path='C:/Users/mod96/Desktop/HSH/StudyingMaterials/Project - datascience/dataset/'\n",
    "save_path='C:/Users/mod96/Desktop/HSH/StudyingMaterials/Project - datascience/models/'\n",
    "trustval_path='C:/Users/mod96/Desktop/HSH/StudyingMaterials/Project - datascience/trustvalue/'\n",
    "seq_length=50\n",
    "TARGET=2  #0: 종가 1: 시가 2: 고가 3: 저가  -  모델이 목표로 하는 값\n",
    "Today_TARGET=0  #0: 종가 1: 시가 2: 고가 3: 저가  -  내일 TARGET 과 비교해서 수익률을 계산할 오늘의 값\n",
    "########################################################################################\n",
    "def datapreparation(KEY_path):\n",
    "    data=pd.read_csv(open(KEY_path))\n",
    "    if int(data.loc[0,'거래량'])==0:          #FaceDivision 처리할 때 index out of range 를 방지하기 위함.\n",
    "        data.loc[0,'거래량']=1\n",
    "    if int(data.loc[data.shape[0]-1,'거래량'])==0:\n",
    "        data.loc[data.shape[0]-1,'거래량']=1\n",
    "    data.drop(['Unnamed: 0','전일비','날짜'],axis=1,inplace=True)\n",
    "    data=data.reindex(index=data.index[::-1])\n",
    "\n",
    "    return data\n",
    "\n",
    "def FaceDivision(df):\n",
    "    if np.isnan(df.to_numpy()).any():\n",
    "        print(\"there exist NaN in raw data\")\n",
    "        print(df[df==np.nan])\n",
    "        raise NotImplementedError\n",
    "    if df.loc[0,'시가']==0:            #거래정지처리\n",
    "        df.loc[0,'시가']=df.loc[0,'종가']\n",
    "    temp1=pd.DataFrame(df.to_numpy(),columns=df.columns)\n",
    "    temp2=temp1.drop('거래량',axis=1)\n",
    "    index1=list(temp1[temp1['거래량']==0].index) \n",
    "    #비인기주는 아무도 관심을 주지 않아(...) 거래량이 0인 경우도 있다.\n",
    "    #또한 액면분할은 여러번 있을 수 있다.\n",
    "    \n",
    "    idx=[]\n",
    "    for i in range(len(index1)-1):\n",
    "        if index1[i+1]-index1[i]>1:\n",
    "            idx.append(int(i))\n",
    "    idx.insert(0,-1)\n",
    "    DivisionDays=[]\n",
    "    for i in range(len(idx)-1):\n",
    "        DivisionDays.append(index1[idx[i]+1:idx[i+1]+1])\n",
    "    DivisionDays.append(index1[idx[-1]+1:])\n",
    "    if len(DivisionDays[0])>0:\n",
    "        for i in range(len(DivisionDays)):\n",
    "            beforeDivision=temp2.loc[DivisionDays[i][0]-1,'종가']\n",
    "            afterDivision=temp2.loc[DivisionDays[i][-1]+1,'시가']\n",
    "            ratio=afterDivision/beforeDivision\n",
    "            if 1/ratio>=1.5:                       #after 에 비해 before 가 1.5 배 이상이면 액면분할이라 가정\n",
    "                temp2.loc[:DivisionDays[i][-1]]=temp2.loc[:DivisionDays[i][-1]]*ratio   #df의 slicing 은 거기까지 포함한다.\n",
    "    \n",
    "    return temp2\n",
    "\n",
    "def Emptyfill(df):            #종가가 모두 존재한다는 가정 하에 시가/고가/저가 항목이 비어있으면 채워준다.\n",
    "    temp=np.array(df.loc[:,'종가'])\n",
    "    temp=np.where(temp==0,np.nan,temp)\n",
    "    assert ~np.isnan(temp).any(), \"there exist 0 in '종가' column\"\n",
    "    \n",
    "    for item in ['시가','고가','저가']:\n",
    "        index1=list(df[df[item].map(int)==0].index)\n",
    "        for each in index1:\n",
    "            df.loc[each,item]=df.loc[each,'종가']\n",
    "    \n",
    "    return df\n",
    "\n",
    "def Prediction(code):\n",
    "    ###########################################################ImportModel\n",
    "    model=tf.keras.models.load_model(save_path+code+'.h5')\n",
    "    ###########################################################ImportTrustValue\n",
    "    T=float(  open(trustval_path+code+'.txt').readline()  )\n",
    "    ###########################################################\n",
    "    data=Emptyfill( FaceDivision( datapreparation(path+code+'.csv') ) )\n",
    "    data=data.iloc[data.shape[0]-seq_length:,:].to_numpy()\n",
    "    Today=list(data[-1,:])\n",
    "    temp=[]\n",
    "    for i in range(data.shape[1]):\n",
    "        denominator=float(data[0,i])\n",
    "        data[:,i]=(data[:,i]/denominator)-1\n",
    "        temp.append(denominator)\n",
    "    ###########################################################\n",
    "    data=data.reshape((1,seq_length,4))\n",
    "    y=model.predict(data)\n",
    "    TomorrowHigh=(y+1)*temp[TARGET]\n",
    "    r=float(TomorrowHigh-Today[Today_TARGET])/float(Today[Today_TARGET])\n",
    "    trusted=float(r*T)\n",
    "    \n",
    "    return Today,TomorrowHigh,r,trusted\n",
    "\n",
    "import glob\n",
    "files=glob.glob(save_path[:-1]+'/*.h5')\n",
    "codeNtrusted={}\n",
    "for codepath in files:\n",
    "    try:\n",
    "        code=codepath.replace('\\\\','/')[-9:-3]\n",
    "        print('processing with code :',code)\n",
    "        with tf.device('/device:GPU:0'):\n",
    "            _,_,_,trusted=Prediction(code)\n",
    "        codeNtrusted.setdefault(trusted,[]).append(code)\n",
    "    except KeyboardInterrupt:\n",
    "        import sys\n",
    "        sys.exit(0)\n",
    "    except:\n",
    "        print('Prediction about index',code,'failed. Pass')\n",
    "        pass\n",
    "\n",
    "MaximumTrust=max(codeNtrusted.keys())\n",
    "codes=codeNtrusted[MaximumTrust]\n",
    "for code in codes:\n",
    "    with tf.device('/device:GPU:0'):\n",
    "    Today,TomorrowHigh,r,trusted=Prediction(code)\n",
    "    print(\"code :\",code,\"Today :\",Today,\"Predicted Tomorrow High :\",int(TomorrowHigh[0]),'Predicted benefit : {}'.format(r*100),'Corr :',trusted/r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "삼성 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing with code : 005930\n",
      "code : 005930 Today : [50000.0, 49900.0, 50500.0, 49600.0] Predicted Tomorrow High : 50986 Predicted benefit : 1.972296875 Corr : 0.29932204\n"
     ]
    }
   ],
   "source": [
    "#모델을 불러오고 다음 값을 얻어내는 코드\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "########################################################################################\n",
    "path='C:/Users/mod96/Desktop/HSH/StudyingMaterials/Project - datascience/dataset/'\n",
    "save_path='C:/Users/mod96/Desktop/HSH/StudyingMaterials/Project - datascience/models/'\n",
    "trustval_path='C:/Users/mod96/Desktop/HSH/StudyingMaterials/Project - datascience/trustvalue/'\n",
    "seq_length=50\n",
    "TARGET=2  #0: 종가 1: 시가 2: 고가 3: 저가  -  모델이 목표로 하는 값\n",
    "Today_TARGET=0  #0: 종가 1: 시가 2: 고가 3: 저가  -  내일 TARGET 과 비교해서 수익률을 계산할 오늘의 값\n",
    "########################################################################################\n",
    "def datapreparation(KEY_path):\n",
    "    data=pd.read_csv(open(KEY_path))\n",
    "    if int(data.loc[0,'거래량'])==0:          #FaceDivision 처리할 때 index out of range 를 방지하기 위함.\n",
    "        data.loc[0,'거래량']=1\n",
    "    if int(data.loc[data.shape[0]-1,'거래량'])==0:\n",
    "        data.loc[data.shape[0]-1,'거래량']=1\n",
    "    data.drop(['Unnamed: 0','전일비','날짜'],axis=1,inplace=True)\n",
    "    data=data.reindex(index=data.index[::-1])\n",
    "\n",
    "    return data\n",
    "\n",
    "def FaceDivision(df):\n",
    "    if np.isnan(df.to_numpy()).any():\n",
    "        print(\"there exist NaN in raw data\")\n",
    "        print(df[df==np.nan])\n",
    "        raise NotImplementedError\n",
    "    if df.loc[0,'시가']==0:            #거래정지처리\n",
    "        df.loc[0,'시가']=df.loc[0,'종가']\n",
    "    temp1=pd.DataFrame(df.to_numpy(),columns=df.columns)\n",
    "    temp2=temp1.drop('거래량',axis=1)\n",
    "    index1=list(temp1[temp1['거래량']==0].index) \n",
    "    #비인기주는 아무도 관심을 주지 않아(...) 거래량이 0인 경우도 있다.\n",
    "    #또한 액면분할은 여러번 있을 수 있다.\n",
    "    \n",
    "    idx=[]\n",
    "    for i in range(len(index1)-1):\n",
    "        if index1[i+1]-index1[i]>1:\n",
    "            idx.append(int(i))\n",
    "    idx.insert(0,-1)\n",
    "    DivisionDays=[]\n",
    "    for i in range(len(idx)-1):\n",
    "        DivisionDays.append(index1[idx[i]+1:idx[i+1]+1])\n",
    "    DivisionDays.append(index1[idx[-1]+1:])\n",
    "    if len(DivisionDays[0])>0:\n",
    "        for i in range(len(DivisionDays)):\n",
    "            beforeDivision=temp2.loc[DivisionDays[i][0]-1,'종가']\n",
    "            afterDivision=temp2.loc[DivisionDays[i][-1]+1,'시가']\n",
    "            ratio=afterDivision/beforeDivision\n",
    "            if 1/ratio>=1.5:                       #after 에 비해 before 가 1.5 배 이상이면 액면분할이라 가정\n",
    "                temp2.loc[:DivisionDays[i][-1]]=temp2.loc[:DivisionDays[i][-1]]*ratio   #df의 slicing 은 거기까지 포함한다.\n",
    "    \n",
    "    return temp2\n",
    "\n",
    "def Emptyfill(df):            #종가가 모두 존재한다는 가정 하에 시가/고가/저가 항목이 비어있으면 채워준다.\n",
    "    temp=np.array(df.loc[:,'종가'])\n",
    "    temp=np.where(temp==0,np.nan,temp)\n",
    "    assert ~np.isnan(temp).any(), \"there exist 0 in '종가' column\"\n",
    "    \n",
    "    for item in ['시가','고가','저가']:\n",
    "        index1=list(df[df[item].map(int)==0].index)\n",
    "        for each in index1:\n",
    "            df.loc[each,item]=df.loc[each,'종가']\n",
    "    \n",
    "    return df\n",
    "\n",
    "def Prediction(code):\n",
    "    ###########################################################ImportModel\n",
    "    model=tf.keras.models.load_model(save_path+code+'.h5')\n",
    "    ###########################################################ImportTrustValue\n",
    "    T=float(  open(trustval_path+code+'.txt').readline()  )\n",
    "    ###########################################################\n",
    "    data=Emptyfill( FaceDivision( datapreparation(path+code+'.csv') ) )\n",
    "    data=data.iloc[data.shape[0]-seq_length:,:].to_numpy()\n",
    "    Today=list(data[-1,:])\n",
    "    temp=[]\n",
    "    for i in range(data.shape[1]):\n",
    "        denominator=float(data[0,i])\n",
    "        data[:,i]=(data[:,i]/denominator)-1\n",
    "        temp.append(denominator)\n",
    "    ###########################################################\n",
    "    data=data.reshape((1,seq_length,4))\n",
    "    y=model.predict(data)\n",
    "    TomorrowHigh=(y+1)*temp[TARGET]\n",
    "    r=float(TomorrowHigh-Today[Today_TARGET])/float(Today[Today_TARGET])\n",
    "    trusted=float(r*T)\n",
    "    \n",
    "    return Today,TomorrowHigh,r,trusted\n",
    "\n",
    "files=['C:/Users/mod96/Desktop/HSH/StudyingMaterials/Project - datascience/models/005930.h5']\n",
    "codeNtrusted={}\n",
    "for codepath in files:\n",
    "    try:\n",
    "        code=codepath.replace('\\\\','/')[-9:-3]\n",
    "        print('processing with code :',code)\n",
    "        _,_,_,trusted=Prediction(code)\n",
    "        codeNtrusted.setdefault(trusted,[]).append(code)\n",
    "    except KeyboardInterrupt:\n",
    "        import sys\n",
    "        sys.exit(0)\n",
    "    except:\n",
    "        print('ERROR')\n",
    "        pass\n",
    "\n",
    "MaximumTrust=max(codeNtrusted.keys())\n",
    "codes=codeNtrusted[MaximumTrust]\n",
    "for code in codes:\n",
    "    Today,TomorrowHigh,r,trusted=Prediction(code)\n",
    "    print(\"code :\",code,\"Today :\",Today,\"Predicted Tomorrow High :\",int(TomorrowHigh[0]),'Predicted benefit : {}'.format(r*100),'Corr :',trusted/r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
