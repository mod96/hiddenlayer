{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ComputerVision - 3.ipynb","provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyOVOM2KRtPfAJzyJcP7DQi4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"2F7zX7ZjMQGo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":372},"executionInfo":{"status":"ok","timestamp":1599466875751,"user_tz":-540,"elapsed":1091,"user":{"displayName":"hidden layer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrHHywJ_Exb4bDD-oZuVoBeLGVG6UVP_5rLMLy=s64","userId":"10845630574575992288"}},"outputId":"626d5675-5a14-4ca2-885b-f47ab8fd0fb7"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mon Sep  7 08:21:14 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0    24W / 300W |      0MiB / 16130MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zS6t39hVMU-v","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1599466879927,"user_tz":-540,"elapsed":2572,"user":{"displayName":"hidden layer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrHHywJ_Exb4bDD-oZuVoBeLGVG6UVP_5rLMLy=s64","userId":"10845630574575992288"}},"outputId":"2627b500-f8f9-4024-fc9f-5d027c5a0559"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive',force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sSFUmyeEMU8f","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1599224954361,"user_tz":-540,"elapsed":8799,"user":{"displayName":"hidden layer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrHHywJ_Exb4bDD-oZuVoBeLGVG6UVP_5rLMLy=s64","userId":"10845630574575992288"}},"outputId":"5c987f09-b68f-4bb9-9694-c88a1f17fd4f"},"source":["import pandas as pd\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","\n","%tensorflow_version 2.x\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import LearningRateScheduler\n","from tensorflow.keras import layers, Sequential\n","\n","from sklearn.model_selection import train_test_split\n","import string\n","\n","path = '/content/gdrive/My Drive/Dacon/ComputerVision/'\n","\n","path_train = path + 'train.csv'\n","path_test = path + 'test.csv'\n","path_submission = path + 'submission.csv'\n","\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","    raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"P1q6iYtCMU6x","colab_type":"code","colab":{}},"source":["seed = 0\n","tf.random.set_seed(seed)\n","np.random.seed(seed)\n","\n","ImageGen_coeff = 10\n","epochs_num = 30\n","verbose = 2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G31-1qcFMU4K","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1598671268177,"user_tz":-540,"elapsed":14616,"user":{"displayName":"hidden layer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrHHywJ_Exb4bDD-oZuVoBeLGVG6UVP_5rLMLy=s64","userId":"10845630574575992288"}},"outputId":"3b248f72-f644-462f-af0b-7bf8f8ba8196"},"source":["def normalization(df):\n","    for row in range(len(df)):\n","        maxi = df.iloc[row].max()\n","        mini = df.iloc[row].min()\n","        if maxi == mini:\n","            df.iloc[row] = df.iloc[row].apply(lambda x : 0)\n","        else:\n","            df.iloc[row] = df.iloc[row].apply(lambda x : (x - mini)/(maxi - mini))\n","    x = df.values\n","    if not np.any(x > 1.0) and not np.any(x < 0) and not np.any(np.isnan(x)):\n","        print('Boundary Clear')      \n","    return df\n","\n","def ComputerVision_Dataset():\n","    path = '/content/gdrive/My Drive/Dacon/ComputerVision/train.csv'\n","    path_pixel = '/content/gdrive/My Drive/Dacon/ComputerVision/train_bicubic56.csv'\n","    train_ratio = 0.9\n","\n","    train = pd.read_csv(path)\n","    train_pixel = pd.read_csv(path_pixel)\n","\n","    point_to = int(len(train) * train_ratio)\n","\n","    train_data = train.iloc[:point_to]\n","    train_data_pixel = train_pixel.iloc[:point_to]\n","    test_data = train.iloc[point_to:]\n","    test_data_pixel = train_pixel.iloc[point_to:]\n","    letter_hash = dict(zip(string.ascii_uppercase, [[1 if i == j else 0 for j in range(26)] for i in range(26)]))\n","\n","    pix = train_data_pixel.iloc[:, 1:]\n","    pix = normalization(pix).values.reshape(-1, 56, 56, 1)\n","\n","    fix = train_data.iloc[:, 1:3].values\n","\n","    datagenerator = ImageDataGenerator(rotation_range=10, zoom_range=0.10, width_shift_range=0.1,\n","                                       height_shift_range=0.1)\n","    gen = datagenerator.flow(pix, fix, shuffle=False, batch_size=32)\n","    pixel, fixed, batch_index, limit = [], [], 0, 64 * ImageGen_coeff\n","    while batch_index <= limit:\n","        try:\n","            data = gen.next()\n","            pixel += list(data[0])\n","            fixed += list(data[1])\n","            batch_index += 1\n","        except:\n","            print(\"ImageGeneratorError\")\n","            break\n","    fixed_train = np.asarray(fixed)\n","    X_train_pixel = np.asarray(pixel)\n","\n","    Y_train = to_categorical(fixed_train[:, 0], 10)\n","\n","    X_train_label = np.asarray([letter_hash[letter] for letter in fixed_train[:, 1]])\n","\n","    X_valid_pixel = test_data_pixel.iloc[:, 1:]\n","    X_valid_pixel = normalization(X_valid_pixel).values.reshape(-1, 56, 56, 1)\n","    X_valid_label = np.array([letter_hash[letter] for letter in test_data.iloc[:, 2]])\n","    Y_valid = to_categorical(test_data.iloc[:, 1], 10)\n","\n","    return X_train_label, X_train_pixel, Y_train, X_valid_label, X_valid_pixel, Y_valid\n","\n","\n","X_train_label, X_train_pixel, Y_train, X_valid_label, X_valid_pixel, Y_valid = ComputerVision_Dataset()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Boundary Clear\n","Boundary Clear\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"R7xKhnhWMU18","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1598673802259,"user_tz":-540,"elapsed":2521708,"user":{"displayName":"hidden layer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrHHywJ_Exb4bDD-oZuVoBeLGVG6UVP_5rLMLy=s64","userId":"10845630574575992288"}},"outputId":"8677e75e-30d0-41b1-8d85-527bde11292a"},"source":["def train_test_model(X_train_label, X_train_pixel, Y_train, X_valid_label, X_valid_pixel, Y_valid):\n","    print('RESNET50 + BICUBIC56')\n","    resnet50 = tf.keras.applications.ResNet50(include_top=False, weights=None, input_tensor=None, input_shape=(56,56,1),pooling=None)\n","    cnn_mid = layers.GlobalAveragePooling2D()(resnet50.output)\n","    cnn_out = layers.Dense(128, activation = 'relu')(cnn_mid)\n","\n","    dense_input = layers.Input(shape=(26,))\n","    dense_mid = layers.Dense(52, activation = 'relu')(dense_input)\n","    dense_output = layers.Dense(52, activation = 'relu')(dense_mid)\n","    dense_model = tf.keras.Model(inputs=dense_input, outputs=dense_output)\n","\n","    concatenated = layers.concatenate([cnn_out, dense_model.output])\n","    concatenated = layers.Dense(32, activation='relu')(concatenated)\n","    concat_output = layers.Dense(10, activation='softmax')(concatenated)\n","    concat_model = tf.keras.models.Model([resnet50.input, dense_input], concat_output)\n","    concat_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","    with tf.device('/device:GPU:0'):\n","        history = concat_model.fit([X_train_pixel, X_train_label], Y_train, epochs=epochs_num,\n","                            validation_data=([X_valid_pixel, X_valid_label], Y_valid),\n","                            verbose=verbose)\n","    print(\n","        f\"CNN: Epochs={epochs_num:d}, \" +\n","        f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n","        f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n","    )\n","\n","train_test_model(X_train_label, X_train_pixel, Y_train, X_valid_label, X_valid_pixel, Y_valid)\n","\n","def train_test_model(X_train_label, X_train_pixel, Y_train, X_valid_label, X_valid_pixel, Y_valid):\n","    print('RESNET101V2 + BICUBIC56')\n","    resnet50 = tf.keras.applications.ResNet101V2(include_top=False, weights=None, input_tensor=None, input_shape=(56,56,1),pooling=None)\n","    cnn_mid = layers.GlobalAveragePooling2D()(resnet50.output)\n","    cnn_out = layers.Dense(128, activation = 'relu')(cnn_mid)\n","\n","    dense_input = layers.Input(shape=(26,))\n","    dense_mid = layers.Dense(52, activation = 'relu')(dense_input)\n","    dense_output = layers.Dense(52, activation = 'relu')(dense_mid)\n","    dense_model = tf.keras.Model(inputs=dense_input, outputs=dense_output)\n","\n","    concatenated = layers.concatenate([cnn_out, dense_model.output])\n","    concatenated = layers.Dense(32, activation='relu')(concatenated)\n","    concat_output = layers.Dense(10, activation='softmax')(concatenated)\n","    concat_model = tf.keras.models.Model([resnet50.input, dense_input], concat_output)\n","    concat_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","    with tf.device('/device:GPU:0'):\n","        history = concat_model.fit([X_train_pixel, X_train_label], Y_train, epochs=epochs_num,\n","                            validation_data=([X_valid_pixel, X_valid_label], Y_valid),\n","                            verbose=verbose)\n","    print(\n","        f\"CNN: Epochs={epochs_num:d}, \" +\n","        f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n","        f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n","    )\n","\n","train_test_model(X_train_label, X_train_pixel, Y_train, X_valid_label, X_valid_pixel, Y_valid)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["RESNET50 + BICUBIC56\n","Epoch 1/30\n","637/637 - 32s - loss: 1.4935 - accuracy: 0.4855 - val_loss: 3.2753 - val_accuracy: 0.3805\n","Epoch 2/30\n","637/637 - 30s - loss: 0.6386 - accuracy: 0.7908 - val_loss: 1.0318 - val_accuracy: 0.6878\n","Epoch 3/30\n","637/637 - 31s - loss: 0.3858 - accuracy: 0.8741 - val_loss: 0.7961 - val_accuracy: 0.7805\n","Epoch 4/30\n","637/637 - 31s - loss: 0.2867 - accuracy: 0.9047 - val_loss: 0.7269 - val_accuracy: 0.7951\n","Epoch 5/30\n","637/637 - 31s - loss: 0.2142 - accuracy: 0.9292 - val_loss: 0.7150 - val_accuracy: 0.8146\n","Epoch 6/30\n","637/637 - 31s - loss: 0.1852 - accuracy: 0.9382 - val_loss: 1.0670 - val_accuracy: 0.7366\n","Epoch 7/30\n","637/637 - 31s - loss: 0.1527 - accuracy: 0.9511 - val_loss: 0.6766 - val_accuracy: 0.8293\n","Epoch 8/30\n","637/637 - 31s - loss: 0.1295 - accuracy: 0.9583 - val_loss: 0.8370 - val_accuracy: 0.8146\n","Epoch 9/30\n","637/637 - 31s - loss: 0.1140 - accuracy: 0.9623 - val_loss: 0.6067 - val_accuracy: 0.8488\n","Epoch 10/30\n","637/637 - 31s - loss: 0.1152 - accuracy: 0.9632 - val_loss: 0.9429 - val_accuracy: 0.7854\n","Epoch 11/30\n","637/637 - 32s - loss: 0.1006 - accuracy: 0.9688 - val_loss: 0.6206 - val_accuracy: 0.8488\n","Epoch 12/30\n","637/637 - 31s - loss: 0.0935 - accuracy: 0.9710 - val_loss: 0.5089 - val_accuracy: 0.8634\n","Epoch 13/30\n","637/637 - 31s - loss: 0.0636 - accuracy: 0.9798 - val_loss: 0.5848 - val_accuracy: 0.8634\n","Epoch 14/30\n","637/637 - 32s - loss: 0.0669 - accuracy: 0.9799 - val_loss: 0.7354 - val_accuracy: 0.8195\n","Epoch 15/30\n","637/637 - 32s - loss: 0.0793 - accuracy: 0.9760 - val_loss: 0.6886 - val_accuracy: 0.8195\n","Epoch 16/30\n","637/637 - 32s - loss: 0.0676 - accuracy: 0.9796 - val_loss: 0.5669 - val_accuracy: 0.8439\n","Epoch 17/30\n","637/637 - 32s - loss: 0.0467 - accuracy: 0.9856 - val_loss: 0.7401 - val_accuracy: 0.8146\n","Epoch 18/30\n","637/637 - 32s - loss: 0.0542 - accuracy: 0.9823 - val_loss: 1.0802 - val_accuracy: 0.8049\n","Epoch 19/30\n","637/637 - 32s - loss: 0.0573 - accuracy: 0.9830 - val_loss: 0.7177 - val_accuracy: 0.8244\n","Epoch 20/30\n","637/637 - 32s - loss: 0.0366 - accuracy: 0.9882 - val_loss: 0.7293 - val_accuracy: 0.8439\n","Epoch 21/30\n","637/637 - 32s - loss: 0.0468 - accuracy: 0.9865 - val_loss: 0.7899 - val_accuracy: 0.8585\n","Epoch 22/30\n","637/637 - 32s - loss: 0.0364 - accuracy: 0.9900 - val_loss: 0.6974 - val_accuracy: 0.8439\n","Epoch 23/30\n","637/637 - 32s - loss: 0.0403 - accuracy: 0.9880 - val_loss: 0.9354 - val_accuracy: 0.8390\n","Epoch 24/30\n","637/637 - 32s - loss: 0.0294 - accuracy: 0.9915 - val_loss: 0.5601 - val_accuracy: 0.8683\n","Epoch 25/30\n","637/637 - 32s - loss: 0.0390 - accuracy: 0.9892 - val_loss: 0.8685 - val_accuracy: 0.8341\n","Epoch 26/30\n","637/637 - 32s - loss: 0.0280 - accuracy: 0.9920 - val_loss: 0.6736 - val_accuracy: 0.8732\n","Epoch 27/30\n","637/637 - 32s - loss: 0.0351 - accuracy: 0.9899 - val_loss: 0.8598 - val_accuracy: 0.8341\n","Epoch 28/30\n","637/637 - 32s - loss: 0.0364 - accuracy: 0.9895 - val_loss: 0.6839 - val_accuracy: 0.8683\n","Epoch 29/30\n","637/637 - 32s - loss: 0.0240 - accuracy: 0.9930 - val_loss: 0.8635 - val_accuracy: 0.8439\n","Epoch 30/30\n","637/637 - 32s - loss: 0.0209 - accuracy: 0.9931 - val_loss: 0.8006 - val_accuracy: 0.8488\n","CNN: Epochs=30, Train accuracy=0.99313, Validation accuracy=0.87317\n","RESNET101V2 + BICUBIC56\n","Epoch 1/30\n","637/637 - 53s - loss: 1.4968 - accuracy: 0.4785 - val_loss: 2.9040 - val_accuracy: 0.4244\n","Epoch 2/30\n","637/637 - 52s - loss: 0.6561 - accuracy: 0.7876 - val_loss: 0.6603 - val_accuracy: 0.8000\n","Epoch 3/30\n","637/637 - 52s - loss: 0.4062 - accuracy: 0.8662 - val_loss: 0.8027 - val_accuracy: 0.7756\n","Epoch 4/30\n","637/637 - 52s - loss: 0.2825 - accuracy: 0.9077 - val_loss: 1.0984 - val_accuracy: 0.7317\n","Epoch 5/30\n","637/637 - 52s - loss: 0.2295 - accuracy: 0.9245 - val_loss: 0.7274 - val_accuracy: 0.8293\n","Epoch 6/30\n","637/637 - 52s - loss: 0.1832 - accuracy: 0.9401 - val_loss: 0.8555 - val_accuracy: 0.8439\n","Epoch 7/30\n","637/637 - 52s - loss: 0.1437 - accuracy: 0.9539 - val_loss: 0.6758 - val_accuracy: 0.8390\n","Epoch 8/30\n","637/637 - 52s - loss: 0.1386 - accuracy: 0.9562 - val_loss: 0.7899 - val_accuracy: 0.8146\n","Epoch 9/30\n","637/637 - 52s - loss: 0.1195 - accuracy: 0.9619 - val_loss: 0.5810 - val_accuracy: 0.8634\n","Epoch 10/30\n","637/637 - 52s - loss: 0.1043 - accuracy: 0.9675 - val_loss: 0.7170 - val_accuracy: 0.8195\n","Epoch 11/30\n","637/637 - 52s - loss: 0.0799 - accuracy: 0.9741 - val_loss: 0.8891 - val_accuracy: 0.8293\n","Epoch 12/30\n","637/637 - 52s - loss: 0.0717 - accuracy: 0.9773 - val_loss: 0.6778 - val_accuracy: 0.8780\n","Epoch 13/30\n","637/637 - 52s - loss: 0.0774 - accuracy: 0.9762 - val_loss: 0.8879 - val_accuracy: 0.8293\n","Epoch 14/30\n","637/637 - 52s - loss: 0.0734 - accuracy: 0.9779 - val_loss: 1.1789 - val_accuracy: 0.7902\n","Epoch 15/30\n","637/637 - 52s - loss: 0.0639 - accuracy: 0.9800 - val_loss: 0.5880 - val_accuracy: 0.8780\n","Epoch 16/30\n","637/637 - 52s - loss: 0.0618 - accuracy: 0.9808 - val_loss: 0.6593 - val_accuracy: 0.8537\n","Epoch 17/30\n","637/637 - 52s - loss: 0.0481 - accuracy: 0.9855 - val_loss: 1.0976 - val_accuracy: 0.8244\n","Epoch 18/30\n","637/637 - 52s - loss: 0.0492 - accuracy: 0.9851 - val_loss: 0.7384 - val_accuracy: 0.8488\n","Epoch 19/30\n","637/637 - 52s - loss: 0.0409 - accuracy: 0.9878 - val_loss: 1.0791 - val_accuracy: 0.8293\n","Epoch 20/30\n","637/637 - 52s - loss: 0.0495 - accuracy: 0.9836 - val_loss: 1.0195 - val_accuracy: 0.7951\n","Epoch 21/30\n","637/637 - 52s - loss: 0.0365 - accuracy: 0.9886 - val_loss: 0.7724 - val_accuracy: 0.8488\n","Epoch 22/30\n","637/637 - 52s - loss: 0.0359 - accuracy: 0.9893 - val_loss: 0.8624 - val_accuracy: 0.8537\n","Epoch 23/30\n","637/637 - 52s - loss: 0.0347 - accuracy: 0.9895 - val_loss: 0.8059 - val_accuracy: 0.8439\n","Epoch 24/30\n","637/637 - 52s - loss: 0.0385 - accuracy: 0.9876 - val_loss: 0.9383 - val_accuracy: 0.8390\n","Epoch 25/30\n","637/637 - 52s - loss: 0.0373 - accuracy: 0.9880 - val_loss: 0.6609 - val_accuracy: 0.8488\n","Epoch 26/30\n","637/637 - 52s - loss: 0.0275 - accuracy: 0.9916 - val_loss: 0.9713 - val_accuracy: 0.8244\n","Epoch 27/30\n","637/637 - 52s - loss: 0.0344 - accuracy: 0.9896 - val_loss: 0.6920 - val_accuracy: 0.8634\n","Epoch 28/30\n","637/637 - 52s - loss: 0.0252 - accuracy: 0.9912 - val_loss: 0.6697 - val_accuracy: 0.8732\n","Epoch 29/30\n","637/637 - 52s - loss: 0.0249 - accuracy: 0.9926 - val_loss: 0.9500 - val_accuracy: 0.8585\n","Epoch 30/30\n","637/637 - 52s - loss: 0.0322 - accuracy: 0.9910 - val_loss: 0.9411 - val_accuracy: 0.8293\n","CNN: Epochs=30, Train accuracy=0.99259, Validation accuracy=0.87805\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hTIVVDTpMUz-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1598673870678,"user_tz":-540,"elapsed":39687,"user":{"displayName":"hidden layer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrHHywJ_Exb4bDD-oZuVoBeLGVG6UVP_5rLMLy=s64","userId":"10845630574575992288"}},"outputId":"445aac9c-b6c8-48b3-cdad-578f81078d8c"},"source":["def normalization(df):\n","    for row in range(len(df)):\n","        maxi = df.iloc[row].max()\n","        mini = df.iloc[row].min()\n","        if maxi == mini:\n","            df.iloc[row] = df.iloc[row].apply(lambda x : 0)\n","        else:\n","            df.iloc[row] = df.iloc[row].apply(lambda x : (x - mini)/(maxi - mini))\n","    x = df.values\n","    if not np.any(x > 1.0) and not np.any(x < 0) and not np.any(np.isnan(x)):\n","        print('Boundary Clear')      \n","    return df\n","\n","def ComputerVision_Dataset():\n","    path = '/content/gdrive/My Drive/Dacon/ComputerVision/train.csv'\n","    path_pixel = '/content/gdrive/My Drive/Dacon/ComputerVision/train_bicubic112.csv'\n","    train_ratio = 0.9\n","\n","    train = pd.read_csv(path)\n","    train_pixel = pd.read_csv(path_pixel)\n","\n","    point_to = int(len(train) * train_ratio)\n","\n","    train_data = train.iloc[:point_to]\n","    train_data_pixel = train_pixel.iloc[:point_to]\n","    test_data = train.iloc[point_to:]\n","    test_data_pixel = train_pixel.iloc[point_to:]\n","    letter_hash = dict(zip(string.ascii_uppercase, [[1 if i == j else 0 for j in range(26)] for i in range(26)]))\n","\n","    pix = train_data_pixel.iloc[:, 1:]\n","    pix = normalization(pix).values.reshape(-1, 112, 112, 1)\n","\n","    fix = train_data.iloc[:, 1:3].values\n","\n","    datagenerator = ImageDataGenerator(rotation_range=10, zoom_range=0.10, width_shift_range=0.1,\n","                                       height_shift_range=0.1)\n","    gen = datagenerator.flow(pix, fix, shuffle=False, batch_size=32)\n","    pixel, fixed, batch_index, limit = [], [], 0, 64 * ImageGen_coeff\n","    while batch_index <= limit:\n","        try:\n","            data = gen.next()\n","            pixel += list(data[0])\n","            fixed += list(data[1])\n","            batch_index += 1\n","        except:\n","            print(\"ImageGeneratorError\")\n","            break\n","    fixed_train = np.asarray(fixed)\n","    X_train_pixel = np.asarray(pixel)\n","\n","    Y_train = to_categorical(fixed_train[:, 0], 10)\n","\n","    X_train_label = np.asarray([letter_hash[letter] for letter in fixed_train[:, 1]])\n","\n","    X_valid_pixel = test_data_pixel.iloc[:, 1:]\n","    X_valid_pixel = normalization(X_valid_pixel).values.reshape(-1, 112, 112, 1)\n","    X_valid_label = np.array([letter_hash[letter] for letter in test_data.iloc[:, 2]])\n","    Y_valid = to_categorical(test_data.iloc[:, 1], 10)\n","\n","    return X_train_label, X_train_pixel, Y_train, X_valid_label, X_valid_pixel, Y_valid\n","\n","\n","X_train_label, X_train_pixel, Y_train, X_valid_label, X_valid_pixel, Y_valid = ComputerVision_Dataset()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Boundary Clear\n","Boundary Clear\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vSVHlcvNMUxi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1598685114238,"user_tz":-540,"elapsed":4867893,"user":{"displayName":"hidden layer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrHHywJ_Exb4bDD-oZuVoBeLGVG6UVP_5rLMLy=s64","userId":"10845630574575992288"}},"outputId":"9c5b67ad-d77c-4f94-878d-058752b17161"},"source":["def train_test_model(X_train_label, X_train_pixel, Y_train, X_valid_label, X_valid_pixel, Y_valid):\n","    print('RESNET50 + BICUBIC112')\n","    resnet50 = tf.keras.applications.ResNet50(include_top=False, weights=None, input_tensor=None, input_shape=(112,112,1),pooling=None)\n","    cnn_mid = layers.GlobalAveragePooling2D()(resnet50.output)\n","    cnn_out = layers.Dense(128, activation = 'relu')(cnn_mid)\n","\n","    dense_input = layers.Input(shape=(26,))\n","    dense_mid = layers.Dense(52, activation = 'relu')(dense_input)\n","    dense_output = layers.Dense(52, activation = 'relu')(dense_mid)\n","    dense_model = tf.keras.Model(inputs=dense_input, outputs=dense_output)\n","\n","    concatenated = layers.concatenate([cnn_out, dense_model.output])\n","    concatenated = layers.Dense(32, activation='relu')(concatenated)\n","    concat_output = layers.Dense(10, activation='softmax')(concatenated)\n","    concat_model = tf.keras.models.Model([resnet50.input, dense_input], concat_output)\n","    concat_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","    with tf.device('/device:GPU:0'):\n","        history = concat_model.fit([X_train_pixel, X_train_label], Y_train, epochs=epochs_num,\n","                            validation_data=([X_valid_pixel, X_valid_label], Y_valid),\n","                            verbose=verbose)\n","    print(\n","        f\"CNN: Epochs={epochs_num:d}, \" +\n","        f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n","        f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n","    )\n","\n","train_test_model(X_train_label, X_train_pixel, Y_train, X_valid_label, X_valid_pixel, Y_valid)\n","\n","def train_test_model(X_train_label, X_train_pixel, Y_train, X_valid_label, X_valid_pixel, Y_valid):\n","    print('RESNET101V2 + BICUBIC112')\n","    resnet50 = tf.keras.applications.ResNet101V2(include_top=False, weights=None, input_tensor=None, input_shape=(112,112,1),pooling=None)\n","    cnn_mid = layers.GlobalAveragePooling2D()(resnet50.output)\n","    cnn_out = layers.Dense(128, activation = 'relu')(cnn_mid)\n","\n","    dense_input = layers.Input(shape=(26,))\n","    dense_mid = layers.Dense(52, activation = 'relu')(dense_input)\n","    dense_output = layers.Dense(52, activation = 'relu')(dense_mid)\n","    dense_model = tf.keras.Model(inputs=dense_input, outputs=dense_output)\n","\n","    concatenated = layers.concatenate([cnn_out, dense_model.output])\n","    concatenated = layers.Dense(32, activation='relu')(concatenated)\n","    concat_output = layers.Dense(10, activation='softmax')(concatenated)\n","    concat_model = tf.keras.models.Model([resnet50.input, dense_input], concat_output)\n","    concat_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","    with tf.device('/device:GPU:0'):\n","        history = concat_model.fit([X_train_pixel, X_train_label], Y_train, epochs=epochs_num,\n","                            validation_data=([X_valid_pixel, X_valid_label], Y_valid),\n","                            verbose=verbose)\n","    print(\n","        f\"CNN: Epochs={epochs_num:d}, \" +\n","        f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n","        f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n","    )\n","\n","train_test_model(X_train_label, X_train_pixel, Y_train, X_valid_label, X_valid_pixel, Y_valid)\n","\n","def train_test_model(X_train_label, X_train_pixel, Y_train, X_valid_label, X_valid_pixel, Y_valid):\n","    print('XCEPTION + BICUBIC112')\n","    resnet50 = tf.keras.applications.Xception(include_top=False, weights=None, input_tensor=None, input_shape=(112,112,1),pooling=None)\n","    cnn_mid = layers.GlobalAveragePooling2D()(resnet50.output)\n","    cnn_out = layers.Dense(128, activation = 'relu')(cnn_mid)\n","\n","    dense_input = layers.Input(shape=(26,))\n","    dense_mid = layers.Dense(52, activation = 'relu')(dense_input)\n","    dense_output = layers.Dense(52, activation = 'relu')(dense_mid)\n","    dense_model = tf.keras.Model(inputs=dense_input, outputs=dense_output)\n","\n","    concatenated = layers.concatenate([cnn_out, dense_model.output])\n","    concatenated = layers.Dense(32, activation='relu')(concatenated)\n","    concat_output = layers.Dense(10, activation='softmax')(concatenated)\n","    concat_model = tf.keras.models.Model([resnet50.input, dense_input], concat_output)\n","    concat_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","    with tf.device('/device:GPU:0'):\n","        history = concat_model.fit([X_train_pixel, X_train_label], Y_train, epochs=epochs_num,\n","                            validation_data=([X_valid_pixel, X_valid_label], Y_valid),\n","                            verbose=verbose)\n","    print(\n","        f\"CNN: Epochs={epochs_num:d}, \" +\n","        f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n","        f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n","    )\n","\n","train_test_model(X_train_label, X_train_pixel, Y_train, X_valid_label, X_valid_pixel, Y_valid)\n","\n","def train_test_model(X_train_label, X_train_pixel, Y_train, X_valid_label, X_valid_pixel, Y_valid):\n","    print('INCEPTIONRESNETV2 + BICUBIC112')\n","    resnet50 = tf.keras.applications.InceptionResNetV2(include_top=False, weights=None, input_tensor=None, input_shape=(112,112,1),pooling=None)\n","    cnn_mid = layers.GlobalAveragePooling2D()(resnet50.output)\n","    cnn_out = layers.Dense(128, activation = 'relu')(cnn_mid)\n","\n","    dense_input = layers.Input(shape=(26,))\n","    dense_mid = layers.Dense(52, activation = 'relu')(dense_input)\n","    dense_output = layers.Dense(52, activation = 'relu')(dense_mid)\n","    dense_model = tf.keras.Model(inputs=dense_input, outputs=dense_output)\n","\n","    concatenated = layers.concatenate([cnn_out, dense_model.output])\n","    concatenated = layers.Dense(32, activation='relu')(concatenated)\n","    concat_output = layers.Dense(10, activation='softmax')(concatenated)\n","    concat_model = tf.keras.models.Model([resnet50.input, dense_input], concat_output)\n","    concat_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","    with tf.device('/device:GPU:0'):\n","        history = concat_model.fit([X_train_pixel, X_train_label], Y_train, epochs=epochs_num,\n","                            validation_data=([X_valid_pixel, X_valid_label], Y_valid),\n","                            verbose=verbose)\n","    print(\n","        f\"CNN: Epochs={epochs_num:d}, \" +\n","        f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n","        f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n","    )\n","\n","train_test_model(X_train_label, X_train_pixel, Y_train, X_valid_label, X_valid_pixel, Y_valid)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["RESNET50 + BICUBIC112\n","Epoch 1/30\n","637/637 - 67s - loss: 1.2578 - accuracy: 0.5765 - val_loss: 1.4671 - val_accuracy: 0.5951\n","Epoch 2/30\n","637/637 - 65s - loss: 0.4711 - accuracy: 0.8493 - val_loss: 1.0938 - val_accuracy: 0.7171\n","Epoch 3/30\n","637/637 - 65s - loss: 0.2853 - accuracy: 0.9059 - val_loss: 0.9259 - val_accuracy: 0.7854\n","Epoch 4/30\n","637/637 - 65s - loss: 0.2116 - accuracy: 0.9311 - val_loss: 0.4464 - val_accuracy: 0.8927\n","Epoch 5/30\n","637/637 - 65s - loss: 0.1860 - accuracy: 0.9405 - val_loss: 0.5499 - val_accuracy: 0.8683\n","Epoch 6/30\n","637/637 - 65s - loss: 0.1447 - accuracy: 0.9500 - val_loss: 0.9283 - val_accuracy: 0.8341\n","Epoch 7/30\n","637/637 - 65s - loss: 0.1273 - accuracy: 0.9585 - val_loss: 0.5418 - val_accuracy: 0.8780\n","Epoch 8/30\n","637/637 - 65s - loss: 0.1152 - accuracy: 0.9615 - val_loss: 0.6323 - val_accuracy: 0.8634\n","Epoch 9/30\n","637/637 - 65s - loss: 0.1030 - accuracy: 0.9663 - val_loss: 0.7388 - val_accuracy: 0.8780\n","Epoch 10/30\n","637/637 - 65s - loss: 0.0839 - accuracy: 0.9728 - val_loss: 0.6949 - val_accuracy: 0.8683\n","Epoch 11/30\n","637/637 - 65s - loss: 0.0701 - accuracy: 0.9774 - val_loss: 0.5440 - val_accuracy: 0.8927\n","Epoch 12/30\n","637/637 - 66s - loss: 0.0684 - accuracy: 0.9780 - val_loss: 0.7348 - val_accuracy: 0.8585\n","Epoch 13/30\n","637/637 - 65s - loss: 0.0703 - accuracy: 0.9773 - val_loss: 0.7361 - val_accuracy: 0.8537\n","Epoch 14/30\n","637/637 - 65s - loss: 0.0498 - accuracy: 0.9841 - val_loss: 0.6142 - val_accuracy: 0.8585\n","Epoch 15/30\n","637/637 - 65s - loss: 0.0563 - accuracy: 0.9819 - val_loss: 0.6820 - val_accuracy: 0.8585\n","Epoch 16/30\n","637/637 - 65s - loss: 0.0440 - accuracy: 0.9865 - val_loss: 0.4125 - val_accuracy: 0.9122\n","Epoch 17/30\n","637/637 - 65s - loss: 0.0385 - accuracy: 0.9870 - val_loss: 0.7125 - val_accuracy: 0.8341\n","Epoch 18/30\n","637/637 - 65s - loss: 0.0433 - accuracy: 0.9874 - val_loss: 0.4760 - val_accuracy: 0.8780\n","Epoch 19/30\n","637/637 - 65s - loss: 0.0471 - accuracy: 0.9860 - val_loss: 0.6326 - val_accuracy: 0.9073\n","Epoch 20/30\n","637/637 - 65s - loss: 0.0330 - accuracy: 0.9899 - val_loss: 0.5176 - val_accuracy: 0.8780\n","Epoch 21/30\n","637/637 - 65s - loss: 0.0402 - accuracy: 0.9876 - val_loss: 0.5814 - val_accuracy: 0.9073\n","Epoch 22/30\n","637/637 - 65s - loss: 0.0281 - accuracy: 0.9912 - val_loss: 0.5769 - val_accuracy: 0.8878\n","Epoch 23/30\n","637/637 - 65s - loss: 0.0322 - accuracy: 0.9903 - val_loss: 0.3714 - val_accuracy: 0.9122\n","Epoch 24/30\n","637/637 - 65s - loss: 0.0233 - accuracy: 0.9932 - val_loss: 0.4958 - val_accuracy: 0.8976\n","Epoch 25/30\n","637/637 - 65s - loss: 0.0414 - accuracy: 0.9877 - val_loss: 0.8923 - val_accuracy: 0.8488\n","Epoch 26/30\n","637/637 - 65s - loss: 0.0201 - accuracy: 0.9943 - val_loss: 0.8958 - val_accuracy: 0.8439\n","Epoch 27/30\n","637/637 - 65s - loss: 0.0252 - accuracy: 0.9920 - val_loss: 0.6848 - val_accuracy: 0.8780\n","Epoch 28/30\n","637/637 - 65s - loss: 0.0186 - accuracy: 0.9950 - val_loss: 0.6850 - val_accuracy: 0.8829\n","Epoch 29/30\n","637/637 - 65s - loss: 0.0365 - accuracy: 0.9896 - val_loss: 0.5789 - val_accuracy: 0.9024\n","Epoch 30/30\n","637/637 - 65s - loss: 0.0156 - accuracy: 0.9957 - val_loss: 0.6233 - val_accuracy: 0.9024\n","CNN: Epochs=30, Train accuracy=0.99568, Validation accuracy=0.91220\n","RESNET101V2 + BICUBIC112\n","Epoch 1/30\n","637/637 - 107s - loss: 1.1279 - accuracy: 0.6179 - val_loss: 1.5718 - val_accuracy: 0.5902\n","Epoch 2/30\n","637/637 - 105s - loss: 0.4401 - accuracy: 0.8561 - val_loss: 0.7210 - val_accuracy: 0.8195\n","Epoch 3/30\n","637/637 - 105s - loss: 0.2784 - accuracy: 0.9067 - val_loss: 0.5351 - val_accuracy: 0.8488\n","Epoch 4/30\n","637/637 - 105s - loss: 0.2081 - accuracy: 0.9295 - val_loss: 1.9071 - val_accuracy: 0.6390\n","Epoch 5/30\n","637/637 - 105s - loss: 0.1637 - accuracy: 0.9459 - val_loss: 0.6041 - val_accuracy: 0.8732\n","Epoch 6/30\n","637/637 - 105s - loss: 0.1351 - accuracy: 0.9563 - val_loss: 0.7626 - val_accuracy: 0.8439\n","Epoch 7/30\n","637/637 - 105s - loss: 0.1142 - accuracy: 0.9618 - val_loss: 0.5271 - val_accuracy: 0.8634\n","Epoch 8/30\n","637/637 - 105s - loss: 0.1186 - accuracy: 0.9607 - val_loss: 0.5816 - val_accuracy: 0.8293\n","Epoch 9/30\n","637/637 - 105s - loss: 0.0851 - accuracy: 0.9699 - val_loss: 0.6593 - val_accuracy: 0.8488\n","Epoch 10/30\n","637/637 - 105s - loss: 0.0775 - accuracy: 0.9742 - val_loss: 0.7839 - val_accuracy: 0.8146\n","Epoch 11/30\n","637/637 - 105s - loss: 0.0719 - accuracy: 0.9770 - val_loss: 0.8217 - val_accuracy: 0.8488\n","Epoch 12/30\n","637/637 - 105s - loss: 0.0604 - accuracy: 0.9797 - val_loss: 0.6045 - val_accuracy: 0.8537\n","Epoch 13/30\n","637/637 - 105s - loss: 0.0497 - accuracy: 0.9837 - val_loss: 0.6142 - val_accuracy: 0.8732\n","Epoch 14/30\n","637/637 - 105s - loss: 0.0570 - accuracy: 0.9823 - val_loss: 0.6896 - val_accuracy: 0.8683\n","Epoch 15/30\n","637/637 - 105s - loss: 0.0460 - accuracy: 0.9852 - val_loss: 0.5748 - val_accuracy: 0.8732\n","Epoch 16/30\n","637/637 - 105s - loss: 0.0520 - accuracy: 0.9833 - val_loss: 0.5112 - val_accuracy: 0.8927\n","Epoch 17/30\n","637/637 - 105s - loss: 0.0334 - accuracy: 0.9902 - val_loss: 0.6565 - val_accuracy: 0.8439\n","Epoch 18/30\n","637/637 - 105s - loss: 0.0441 - accuracy: 0.9858 - val_loss: 0.5726 - val_accuracy: 0.8878\n","Epoch 19/30\n","637/637 - 105s - loss: 0.0362 - accuracy: 0.9883 - val_loss: 0.7471 - val_accuracy: 0.8585\n","Epoch 20/30\n","637/637 - 105s - loss: 0.0367 - accuracy: 0.9887 - val_loss: 0.5161 - val_accuracy: 0.8829\n","Epoch 21/30\n","637/637 - 105s - loss: 0.0279 - accuracy: 0.9918 - val_loss: 0.9455 - val_accuracy: 0.8439\n","Epoch 22/30\n","637/637 - 105s - loss: 0.0330 - accuracy: 0.9901 - val_loss: 0.9000 - val_accuracy: 0.8439\n","Epoch 23/30\n","637/637 - 105s - loss: 0.0263 - accuracy: 0.9925 - val_loss: 0.8276 - val_accuracy: 0.8585\n","Epoch 24/30\n","637/637 - 105s - loss: 0.0247 - accuracy: 0.9924 - val_loss: 0.5893 - val_accuracy: 0.9073\n","Epoch 25/30\n","637/637 - 105s - loss: 0.0324 - accuracy: 0.9895 - val_loss: 0.7252 - val_accuracy: 0.8878\n","Epoch 26/30\n","637/637 - 105s - loss: 0.0181 - accuracy: 0.9949 - val_loss: 0.4584 - val_accuracy: 0.8927\n","Epoch 27/30\n","637/637 - 105s - loss: 0.0318 - accuracy: 0.9916 - val_loss: 0.7440 - val_accuracy: 0.8634\n","Epoch 28/30\n","637/637 - 105s - loss: 0.0150 - accuracy: 0.9953 - val_loss: 0.5211 - val_accuracy: 0.8927\n","Epoch 29/30\n","637/637 - 105s - loss: 0.0224 - accuracy: 0.9933 - val_loss: 0.4509 - val_accuracy: 0.8976\n","Epoch 30/30\n","637/637 - 105s - loss: 0.0236 - accuracy: 0.9931 - val_loss: 1.0037 - val_accuracy: 0.8439\n","CNN: Epochs=30, Train accuracy=0.99529, Validation accuracy=0.90732\n","XCEPTION + BICUBIC112\n","Epoch 1/30\n","WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0405s vs `on_train_batch_end` time: 0.1135s). Check your callbacks.\n","637/637 - 102s - loss: 0.9461 - accuracy: 0.6781 - val_loss: 0.8566 - val_accuracy: 0.7610\n","Epoch 2/30\n","637/637 - 101s - loss: 0.2830 - accuracy: 0.9088 - val_loss: 1.0187 - val_accuracy: 0.7902\n","Epoch 3/30\n","637/637 - 102s - loss: 0.1682 - accuracy: 0.9449 - val_loss: 0.8611 - val_accuracy: 0.8049\n","Epoch 4/30\n","637/637 - 101s - loss: 0.1038 - accuracy: 0.9655 - val_loss: 0.5692 - val_accuracy: 0.8732\n","Epoch 5/30\n","637/637 - 101s - loss: 0.0785 - accuracy: 0.9752 - val_loss: 0.4245 - val_accuracy: 0.9024\n","Epoch 6/30\n","637/637 - 101s - loss: 0.0764 - accuracy: 0.9735 - val_loss: 0.8659 - val_accuracy: 0.8049\n","Epoch 7/30\n","637/637 - 101s - loss: 0.0484 - accuracy: 0.9845 - val_loss: 1.0874 - val_accuracy: 0.8293\n","Epoch 8/30\n","637/637 - 102s - loss: 0.0600 - accuracy: 0.9820 - val_loss: 0.9838 - val_accuracy: 0.8146\n","Epoch 9/30\n","637/637 - 102s - loss: 0.0397 - accuracy: 0.9884 - val_loss: 0.6536 - val_accuracy: 0.8537\n","Epoch 10/30\n","637/637 - 102s - loss: 0.0392 - accuracy: 0.9879 - val_loss: 0.8962 - val_accuracy: 0.8683\n","Epoch 11/30\n","637/637 - 101s - loss: 0.0403 - accuracy: 0.9872 - val_loss: 1.0913 - val_accuracy: 0.7951\n","Epoch 12/30\n","637/637 - 101s - loss: 0.0316 - accuracy: 0.9902 - val_loss: 0.7545 - val_accuracy: 0.8439\n","Epoch 13/30\n","637/637 - 101s - loss: 0.0343 - accuracy: 0.9900 - val_loss: 0.5751 - val_accuracy: 0.9024\n","Epoch 14/30\n","637/637 - 102s - loss: 0.0299 - accuracy: 0.9911 - val_loss: 0.6446 - val_accuracy: 0.8976\n","Epoch 15/30\n","637/637 - 103s - loss: 0.0243 - accuracy: 0.9927 - val_loss: 0.5614 - val_accuracy: 0.8927\n","Epoch 16/30\n","637/637 - 101s - loss: 0.0325 - accuracy: 0.9905 - val_loss: 0.7787 - val_accuracy: 0.8780\n","Epoch 17/30\n","637/637 - 101s - loss: 0.0258 - accuracy: 0.9923 - val_loss: 0.7052 - val_accuracy: 0.8927\n","Epoch 18/30\n","637/637 - 101s - loss: 0.0226 - accuracy: 0.9941 - val_loss: 0.8377 - val_accuracy: 0.8829\n","Epoch 19/30\n","637/637 - 101s - loss: 0.0235 - accuracy: 0.9931 - val_loss: 0.7173 - val_accuracy: 0.9171\n","Epoch 20/30\n","637/637 - 101s - loss: 0.0162 - accuracy: 0.9952 - val_loss: 0.5430 - val_accuracy: 0.8829\n","Epoch 21/30\n","637/637 - 101s - loss: 0.0281 - accuracy: 0.9920 - val_loss: 0.4648 - val_accuracy: 0.8829\n","Epoch 22/30\n","637/637 - 101s - loss: 0.0177 - accuracy: 0.9951 - val_loss: 0.5271 - val_accuracy: 0.9024\n","Epoch 23/30\n","637/637 - 101s - loss: 0.0206 - accuracy: 0.9940 - val_loss: 0.5961 - val_accuracy: 0.9024\n","Epoch 24/30\n","637/637 - 101s - loss: 0.0181 - accuracy: 0.9950 - val_loss: 0.5904 - val_accuracy: 0.8780\n","Epoch 25/30\n","637/637 - 102s - loss: 0.0141 - accuracy: 0.9963 - val_loss: 0.5389 - val_accuracy: 0.8927\n","Epoch 26/30\n","637/637 - 101s - loss: 0.0182 - accuracy: 0.9946 - val_loss: 0.9003 - val_accuracy: 0.8390\n","Epoch 27/30\n","637/637 - 102s - loss: 0.0167 - accuracy: 0.9950 - val_loss: 0.7544 - val_accuracy: 0.8780\n","Epoch 28/30\n","637/637 - 102s - loss: 0.0220 - accuracy: 0.9944 - val_loss: 0.5614 - val_accuracy: 0.8976\n","Epoch 29/30\n","637/637 - 101s - loss: 0.0123 - accuracy: 0.9967 - val_loss: 0.5596 - val_accuracy: 0.9024\n","Epoch 30/30\n","637/637 - 102s - loss: 0.0172 - accuracy: 0.9953 - val_loss: 0.5961 - val_accuracy: 0.9122\n","CNN: Epochs=30, Train accuracy=0.99666, Validation accuracy=0.91707\n","INCEPTIONRESNETV2 + BICUBIC112\n","Epoch 1/30\n","637/637 - 105s - loss: 0.7279 - accuracy: 0.7561 - val_loss: 0.8793 - val_accuracy: 0.7610\n","Epoch 2/30\n","637/637 - 101s - loss: 0.2377 - accuracy: 0.9229 - val_loss: 0.6453 - val_accuracy: 0.8537\n","Epoch 3/30\n","637/637 - 101s - loss: 0.1515 - accuracy: 0.9489 - val_loss: 1.6350 - val_accuracy: 0.6537\n","Epoch 4/30\n","637/637 - 100s - loss: 0.0986 - accuracy: 0.9688 - val_loss: 0.4227 - val_accuracy: 0.8878\n","Epoch 5/30\n","637/637 - 100s - loss: 0.0968 - accuracy: 0.9685 - val_loss: 0.6859 - val_accuracy: 0.8439\n","Epoch 6/30\n","637/637 - 100s - loss: 0.0638 - accuracy: 0.9793 - val_loss: 0.5080 - val_accuracy: 0.8976\n","Epoch 7/30\n","637/637 - 100s - loss: 0.0597 - accuracy: 0.9806 - val_loss: 0.4399 - val_accuracy: 0.8829\n","Epoch 8/30\n","637/637 - 100s - loss: 0.0550 - accuracy: 0.9824 - val_loss: 0.6860 - val_accuracy: 0.8537\n","Epoch 9/30\n","637/637 - 100s - loss: 0.0504 - accuracy: 0.9846 - val_loss: 0.5612 - val_accuracy: 0.8780\n","Epoch 10/30\n","637/637 - 100s - loss: 0.0526 - accuracy: 0.9827 - val_loss: 0.8547 - val_accuracy: 0.8341\n","Epoch 11/30\n","637/637 - 100s - loss: 0.0281 - accuracy: 0.9910 - val_loss: 0.7538 - val_accuracy: 0.8927\n","Epoch 12/30\n","637/637 - 100s - loss: 0.0499 - accuracy: 0.9858 - val_loss: 0.5732 - val_accuracy: 0.8927\n","Epoch 13/30\n","637/637 - 100s - loss: 0.0315 - accuracy: 0.9906 - val_loss: 0.9178 - val_accuracy: 0.8195\n","Epoch 14/30\n","637/637 - 100s - loss: 0.0315 - accuracy: 0.9904 - val_loss: 0.6005 - val_accuracy: 0.8927\n","Epoch 15/30\n","637/637 - 100s - loss: 0.0261 - accuracy: 0.9918 - val_loss: 0.6543 - val_accuracy: 0.8634\n","Epoch 16/30\n","637/637 - 100s - loss: 0.0339 - accuracy: 0.9904 - val_loss: 0.5695 - val_accuracy: 0.8878\n","Epoch 17/30\n","637/637 - 100s - loss: 0.0269 - accuracy: 0.9920 - val_loss: 0.6904 - val_accuracy: 0.8976\n","Epoch 18/30\n","637/637 - 100s - loss: 0.0244 - accuracy: 0.9932 - val_loss: 0.4773 - val_accuracy: 0.8976\n","Epoch 19/30\n","637/637 - 100s - loss: 0.0328 - accuracy: 0.9903 - val_loss: 0.5320 - val_accuracy: 0.8927\n","Epoch 20/30\n","637/637 - 100s - loss: 0.0169 - accuracy: 0.9949 - val_loss: 0.6884 - val_accuracy: 0.8780\n","Epoch 21/30\n","637/637 - 100s - loss: 0.0292 - accuracy: 0.9919 - val_loss: 0.7730 - val_accuracy: 0.8683\n","Epoch 22/30\n","637/637 - 100s - loss: 0.0221 - accuracy: 0.9935 - val_loss: 0.6234 - val_accuracy: 0.8927\n","Epoch 23/30\n","637/637 - 100s - loss: 0.0170 - accuracy: 0.9949 - val_loss: 0.6627 - val_accuracy: 0.8537\n","Epoch 24/30\n","637/637 - 100s - loss: 0.0155 - accuracy: 0.9960 - val_loss: 0.6105 - val_accuracy: 0.8878\n","Epoch 25/30\n","637/637 - 100s - loss: 0.0181 - accuracy: 0.9951 - val_loss: 0.4809 - val_accuracy: 0.9073\n","Epoch 26/30\n","637/637 - 100s - loss: 0.0176 - accuracy: 0.9948 - val_loss: 0.4949 - val_accuracy: 0.9024\n","Epoch 27/30\n","637/637 - 100s - loss: 0.0235 - accuracy: 0.9943 - val_loss: 0.4322 - val_accuracy: 0.9122\n","Epoch 28/30\n","637/637 - 100s - loss: 0.0193 - accuracy: 0.9941 - val_loss: 0.6373 - val_accuracy: 0.8732\n","Epoch 29/30\n","637/637 - 100s - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.7535 - val_accuracy: 0.8927\n","Epoch 30/30\n","637/637 - 100s - loss: 0.0216 - accuracy: 0.9944 - val_loss: 0.8706 - val_accuracy: 0.8878\n","CNN: Epochs=30, Train accuracy=0.99794, Validation accuracy=0.91220\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5EmCoR_DheAz","colab_type":"text"},"source":["bicubic 224 test\n","---------------"]},{"cell_type":"code","metadata":{"id":"y_8DsXlXheaH","colab_type":"code","colab":{}},"source":["seed = 0\n","tf.random.set_seed(seed)\n","np.random.seed(seed)\n","\n","ImageGen_coeff = 10\n","epochs_num = 30\n","verbose = 2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ID3EEtfIMUvO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1598752160089,"user_tz":-540,"elapsed":234898,"user":{"displayName":"hidden layer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrHHywJ_Exb4bDD-oZuVoBeLGVG6UVP_5rLMLy=s64","userId":"10845630574575992288"}},"outputId":"c231a286-d603-4e40-e27c-baa143df0ae4"},"source":["N_dim = 224\n","\n","def normalization(df):\n","    for row in range(len(df)):\n","        maxi = df.iloc[row].max()\n","        mini = df.iloc[row].min()\n","        if maxi == mini:\n","            df.iloc[row] = df.iloc[row].apply(lambda x : 0)\n","        else:\n","            df.iloc[row] = df.iloc[row].apply(lambda x : (x - mini)/(maxi - mini))\n","    x = df.values\n","    if not np.any(x > 1.0) and not np.any(x < 0) and not np.any(np.isnan(x)):\n","        print('Boundary Clear')      \n","    return df\n","\n","def ComputerVision_Dataset():\n","    path = '/content/gdrive/My Drive/Dacon/ComputerVision/train.csv'\n","    path_pixel = '/content/gdrive/My Drive/Dacon/ComputerVision/train_bicubic'+str(N_dim)+'.csv'\n","    train_ratio = 0.9\n","\n","    train = pd.read_csv(path)\n","    train_pixel = pd.read_csv(path_pixel)\n","\n","    point_to = int(len(train) * train_ratio)\n","\n","    train_data = train.iloc[:point_to]\n","    train_data_pixel = train_pixel.iloc[:point_to]\n","    test_data = train.iloc[point_to:]\n","    test_data_pixel = train_pixel.iloc[point_to:]\n","    letter_hash = dict(zip(string.ascii_uppercase, [[1 if i == j else 0 for j in range(26)] for i in range(26)]))\n","\n","    pix = train_data_pixel.iloc[:, 1:]\n","    pix = normalization(pix).values.reshape(-1, N_dim, N_dim, 1)\n","\n","    fix = train_data.iloc[:, 1:3].values\n","\n","    datagenerator = ImageDataGenerator(rotation_range=10, zoom_range=0.10, width_shift_range=0.1,\n","                                       height_shift_range=0.1)\n","    gen = datagenerator.flow(pix, fix, shuffle=False, batch_size=32)\n","    pixel, fixed, batch_index, limit = [], [], 0, 64 * ImageGen_coeff\n","    while batch_index <= limit:\n","        try:\n","            data = gen.next()\n","            pixel += list(data[0])\n","            fixed += list(data[1])\n","            batch_index += 1\n","        except:\n","            print(\"ImageGeneratorError\")\n","            break\n","    fixed_train = np.asarray(fixed)\n","    X_train_pixel = np.asarray(pixel)\n","\n","    Y_train = to_categorical(fixed_train[:, 0], 10)\n","\n","    X_train_label = np.asarray([letter_hash[letter] for letter in fixed_train[:, 1]])\n","\n","    X_valid_pixel = test_data_pixel.iloc[:, 1:]\n","    X_valid_pixel = normalization(X_valid_pixel).values.reshape(-1, N_dim, N_dim, 1)\n","    X_valid_label = np.array([letter_hash[letter] for letter in test_data.iloc[:, 2]])\n","    Y_valid = to_categorical(test_data.iloc[:, 1], 10)\n","\n","    return X_train_label, X_train_pixel, Y_train, X_valid_label, X_valid_pixel, Y_valid\n","\n","\n","X_train_label, X_train_pixel, Y_train, X_valid_label, X_valid_pixel, Y_valid = ComputerVision_Dataset()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Boundary Clear\n","Boundary Clear\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pAh-zbPGMUtH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1598773834009,"user_tz":-540,"elapsed":1757517,"user":{"displayName":"hidden layer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrHHywJ_Exb4bDD-oZuVoBeLGVG6UVP_5rLMLy=s64","userId":"10845630574575992288"}},"outputId":"72b8f4b7-4536-49a5-c264-da494e15e92a"},"source":["def train_test_model(X_train_label, X_train_pixel, Y_train, X_valid_label, X_valid_pixel, Y_valid):\n","    print('RESNET50 + BICUBIC112')\n","    resnet50 = tf.keras.applications.ResNet50(include_top=False, weights=None, input_tensor=None, input_shape=(N_dim,N_dim,1),pooling=None)\n","    cnn_mid = layers.GlobalAveragePooling2D()(resnet50.output)\n","    cnn_out = layers.Dense(128, activation = 'relu')(cnn_mid)\n","\n","    dense_input = layers.Input(shape=(26,))\n","    dense_mid = layers.Dense(52, activation = 'relu')(dense_input)\n","    dense_output = layers.Dense(52, activation = 'relu')(dense_mid)\n","    dense_model = tf.keras.Model(inputs=dense_input, outputs=dense_output)\n","\n","    concatenated = layers.concatenate([cnn_out, dense_model.output])\n","    concatenated = layers.Dense(32, activation='relu')(concatenated)\n","    concat_output = layers.Dense(10, activation='softmax')(concatenated)\n","    concat_model = tf.keras.models.Model([resnet50.input, dense_input], concat_output)\n","    concat_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","    with tf.device('/device:GPU:0'):\n","        history = concat_model.fit([X_train_pixel, X_train_label], Y_train, epochs=epochs_num,\n","                            validation_data=([X_valid_pixel, X_valid_label], Y_valid),\n","                            verbose=verbose)\n","    print(\n","        f\"CNN: Epochs={epochs_num:d}, \" +\n","        f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n","        f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n","    )\n","\n","train_test_model(X_train_label, X_train_pixel, Y_train, X_valid_label, X_valid_pixel, Y_valid)\n","\n","def train_test_model(X_train_label, X_train_pixel, Y_train, X_valid_label, X_valid_pixel, Y_valid):\n","    print('RESNET101V2 + BICUBIC112')\n","    resnet50 = tf.keras.applications.ResNet101V2(include_top=False, weights=None, input_tensor=None, input_shape=(N_dim,N_dim,1),pooling=None)\n","    cnn_mid = layers.GlobalAveragePooling2D()(resnet50.output)\n","    cnn_out = layers.Dense(128, activation = 'relu')(cnn_mid)\n","\n","    dense_input = layers.Input(shape=(26,))\n","    dense_mid = layers.Dense(52, activation = 'relu')(dense_input)\n","    dense_output = layers.Dense(52, activation = 'relu')(dense_mid)\n","    dense_model = tf.keras.Model(inputs=dense_input, outputs=dense_output)\n","\n","    concatenated = layers.concatenate([cnn_out, dense_model.output])\n","    concatenated = layers.Dense(32, activation='relu')(concatenated)\n","    concat_output = layers.Dense(10, activation='softmax')(concatenated)\n","    concat_model = tf.keras.models.Model([resnet50.input, dense_input], concat_output)\n","    concat_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","    with tf.device('/device:GPU:0'):\n","        history = concat_model.fit([X_train_pixel, X_train_label], Y_train, epochs=epochs_num,\n","                            validation_data=([X_valid_pixel, X_valid_label], Y_valid),\n","                            verbose=verbose)\n","    print(\n","        f\"CNN: Epochs={epochs_num:d}, \" +\n","        f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n","        f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n","    )\n","\n","train_test_model(X_train_label, X_train_pixel, Y_train, X_valid_label, X_valid_pixel, Y_valid)\n","\n","def train_test_model(X_train_label, X_train_pixel, Y_train, X_valid_label, X_valid_pixel, Y_valid):\n","    print('XCEPTION + BICUBIC112')\n","    resnet50 = tf.keras.applications.Xception(include_top=False, weights=None, input_tensor=None, input_shape=(N_dim,N_dim,1),pooling=None)\n","    cnn_mid = layers.GlobalAveragePooling2D()(resnet50.output)\n","    cnn_out = layers.Dense(128, activation = 'relu')(cnn_mid)\n","\n","    dense_input = layers.Input(shape=(26,))\n","    dense_mid = layers.Dense(52, activation = 'relu')(dense_input)\n","    dense_output = layers.Dense(52, activation = 'relu')(dense_mid)\n","    dense_model = tf.keras.Model(inputs=dense_input, outputs=dense_output)\n","\n","    concatenated = layers.concatenate([cnn_out, dense_model.output])\n","    concatenated = layers.Dense(32, activation='relu')(concatenated)\n","    concat_output = layers.Dense(10, activation='softmax')(concatenated)\n","    concat_model = tf.keras.models.Model([resnet50.input, dense_input], concat_output)\n","    concat_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","    with tf.device('/device:GPU:0'):\n","        history = concat_model.fit([X_train_pixel, X_train_label], Y_train, epochs=epochs_num,\n","                            validation_data=([X_valid_pixel, X_valid_label], Y_valid),\n","                            verbose=verbose)\n","    print(\n","        f\"CNN: Epochs={epochs_num:d}, \" +\n","        f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n","        f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n","    )\n","\n","train_test_model(X_train_label, X_train_pixel, Y_train, X_valid_label, X_valid_pixel, Y_valid)\n","\n","def train_test_model(X_train_label, X_train_pixel, Y_train, X_valid_label, X_valid_pixel, Y_valid):\n","    print('INCEPTIONRESNETV2 + BICUBIC112')\n","    resnet50 = tf.keras.applications.InceptionResNetV2(include_top=False, weights=None, input_tensor=None, input_shape=(N_dim,N_dim,1),pooling=None)\n","    cnn_mid = layers.GlobalAveragePooling2D()(resnet50.output)\n","    cnn_out = layers.Dense(128, activation = 'relu')(cnn_mid)\n","\n","    dense_input = layers.Input(shape=(26,))\n","    dense_mid = layers.Dense(52, activation = 'relu')(dense_input)\n","    dense_output = layers.Dense(52, activation = 'relu')(dense_mid)\n","    dense_model = tf.keras.Model(inputs=dense_input, outputs=dense_output)\n","\n","    concatenated = layers.concatenate([cnn_out, dense_model.output])\n","    concatenated = layers.Dense(32, activation='relu')(concatenated)\n","    concat_output = layers.Dense(10, activation='softmax')(concatenated)\n","    concat_model = tf.keras.models.Model([resnet50.input, dense_input], concat_output)\n","    concat_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","    with tf.device('/device:GPU:0'):\n","        history = concat_model.fit([X_train_pixel, X_train_label], Y_train, epochs=epochs_num,\n","                            validation_data=([X_valid_pixel, X_valid_label], Y_valid),\n","                            verbose=verbose)\n","    print(\n","        f\"CNN: Epochs={epochs_num:d}, \" +\n","        f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n","        f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n","    )\n","\n","train_test_model(X_train_label, X_train_pixel, Y_train, X_valid_label, X_valid_pixel, Y_valid)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["RESNET50 + BICUBIC112\n","Epoch 1/30\n","637/637 - 106s - loss: 1.2263 - accuracy: 0.5755 - val_loss: 1.6606 - val_accuracy: 0.6098\n","Epoch 2/30\n","637/637 - 104s - loss: 0.4229 - accuracy: 0.8634 - val_loss: 0.7325 - val_accuracy: 0.8049\n","Epoch 3/30\n","637/637 - 104s - loss: 0.2636 - accuracy: 0.9117 - val_loss: 0.5220 - val_accuracy: 0.8488\n","Epoch 4/30\n","637/637 - 104s - loss: 0.1956 - accuracy: 0.9331 - val_loss: 1.3291 - val_accuracy: 0.7366\n","Epoch 5/30\n","637/637 - 104s - loss: 0.1525 - accuracy: 0.9480 - val_loss: 0.9488 - val_accuracy: 0.8000\n","Epoch 6/30\n","637/637 - 104s - loss: 0.1318 - accuracy: 0.9564 - val_loss: 0.5332 - val_accuracy: 0.8780\n","Epoch 7/30\n","637/637 - 104s - loss: 0.0947 - accuracy: 0.9683 - val_loss: 0.6883 - val_accuracy: 0.8878\n","Epoch 8/30\n","637/637 - 104s - loss: 0.0930 - accuracy: 0.9690 - val_loss: 0.6965 - val_accuracy: 0.8439\n","Epoch 9/30\n","637/637 - 104s - loss: 0.0791 - accuracy: 0.9746 - val_loss: 0.6005 - val_accuracy: 0.8829\n","Epoch 10/30\n","637/637 - 104s - loss: 0.0752 - accuracy: 0.9750 - val_loss: 0.4107 - val_accuracy: 0.8927\n","Epoch 11/30\n","637/637 - 104s - loss: 0.0621 - accuracy: 0.9792 - val_loss: 0.7340 - val_accuracy: 0.8683\n","Epoch 12/30\n","637/637 - 104s - loss: 0.0509 - accuracy: 0.9833 - val_loss: 1.2424 - val_accuracy: 0.8000\n","Epoch 13/30\n","637/637 - 104s - loss: 0.0629 - accuracy: 0.9793 - val_loss: 0.6556 - val_accuracy: 0.8634\n","Epoch 14/30\n","637/637 - 104s - loss: 0.0454 - accuracy: 0.9861 - val_loss: 1.0807 - val_accuracy: 0.8488\n","Epoch 15/30\n","637/637 - 104s - loss: 0.0427 - accuracy: 0.9862 - val_loss: 0.5731 - val_accuracy: 0.8829\n","Epoch 16/30\n","637/637 - 104s - loss: 0.0386 - accuracy: 0.9877 - val_loss: 0.5383 - val_accuracy: 0.8976\n","Epoch 17/30\n","637/637 - 104s - loss: 0.0332 - accuracy: 0.9897 - val_loss: 0.7983 - val_accuracy: 0.8780\n","Epoch 18/30\n","637/637 - 104s - loss: 0.0428 - accuracy: 0.9862 - val_loss: 0.6397 - val_accuracy: 0.8634\n","Epoch 19/30\n","637/637 - 104s - loss: 0.0322 - accuracy: 0.9897 - val_loss: 0.5909 - val_accuracy: 0.8878\n","Epoch 20/30\n","637/637 - 104s - loss: 0.0281 - accuracy: 0.9919 - val_loss: 0.4566 - val_accuracy: 0.9171\n","Epoch 21/30\n","637/637 - 104s - loss: 0.0204 - accuracy: 0.9931 - val_loss: 0.4527 - val_accuracy: 0.9024\n","Epoch 22/30\n","637/637 - 104s - loss: 0.0408 - accuracy: 0.9872 - val_loss: 0.7489 - val_accuracy: 0.8732\n","Epoch 23/30\n","637/637 - 104s - loss: 0.0289 - accuracy: 0.9910 - val_loss: 0.5405 - val_accuracy: 0.8976\n","Epoch 24/30\n","637/637 - 104s - loss: 0.0222 - accuracy: 0.9930 - val_loss: 0.6244 - val_accuracy: 0.8780\n","Epoch 25/30\n","637/637 - 104s - loss: 0.0178 - accuracy: 0.9948 - val_loss: 0.7526 - val_accuracy: 0.8683\n","Epoch 26/30\n","637/637 - 104s - loss: 0.0255 - accuracy: 0.9928 - val_loss: 0.7054 - val_accuracy: 0.8878\n","Epoch 27/30\n","637/637 - 104s - loss: 0.0257 - accuracy: 0.9920 - val_loss: 0.4983 - val_accuracy: 0.8976\n","Epoch 28/30\n","637/637 - 104s - loss: 0.0184 - accuracy: 0.9944 - val_loss: 0.5140 - val_accuracy: 0.8829\n","Epoch 29/30\n","637/637 - 104s - loss: 0.0230 - accuracy: 0.9938 - val_loss: 0.5999 - val_accuracy: 0.8927\n","Epoch 30/30\n","637/637 - 104s - loss: 0.0198 - accuracy: 0.9942 - val_loss: 0.6709 - val_accuracy: 0.8732\n","CNN: Epochs=30, Train accuracy=0.99485, Validation accuracy=0.91707\n","RESNET101V2 + BICUBIC112\n","Epoch 1/30\n","637/637 - 165s - loss: 0.9857 - accuracy: 0.6615 - val_loss: 1.1873 - val_accuracy: 0.6390\n","Epoch 2/30\n","637/637 - 164s - loss: 0.3925 - accuracy: 0.8692 - val_loss: 1.1296 - val_accuracy: 0.7512\n","Epoch 3/30\n","637/637 - 165s - loss: 0.2534 - accuracy: 0.9137 - val_loss: 1.1104 - val_accuracy: 0.7366\n","Epoch 4/30\n","637/637 - 165s - loss: 0.1790 - accuracy: 0.9394 - val_loss: 0.6847 - val_accuracy: 0.8244\n","Epoch 5/30\n","637/637 - 165s - loss: 0.1416 - accuracy: 0.9513 - val_loss: 0.4230 - val_accuracy: 0.9024\n","Epoch 6/30\n","637/637 - 165s - loss: 0.1093 - accuracy: 0.9621 - val_loss: 0.6982 - val_accuracy: 0.8732\n","Epoch 7/30\n","637/637 - 164s - loss: 0.0910 - accuracy: 0.9696 - val_loss: 0.7973 - val_accuracy: 0.8537\n","Epoch 8/30\n","637/637 - 164s - loss: 0.0930 - accuracy: 0.9694 - val_loss: 0.4716 - val_accuracy: 0.8829\n","Epoch 9/30\n","637/637 - 164s - loss: 0.0628 - accuracy: 0.9785 - val_loss: 0.9097 - val_accuracy: 0.8195\n","Epoch 10/30\n","637/637 - 164s - loss: 0.0754 - accuracy: 0.9752 - val_loss: 0.6984 - val_accuracy: 0.8780\n","Epoch 11/30\n","637/637 - 165s - loss: 0.0547 - accuracy: 0.9816 - val_loss: 0.7827 - val_accuracy: 0.8780\n","Epoch 12/30\n","637/637 - 164s - loss: 0.0519 - accuracy: 0.9831 - val_loss: 0.3698 - val_accuracy: 0.8829\n","Epoch 13/30\n","637/637 - 165s - loss: 0.0593 - accuracy: 0.9810 - val_loss: 0.5903 - val_accuracy: 0.8439\n","Epoch 14/30\n","637/637 - 165s - loss: 0.0302 - accuracy: 0.9903 - val_loss: 0.8043 - val_accuracy: 0.8585\n","Epoch 15/30\n","637/637 - 165s - loss: 0.0388 - accuracy: 0.9867 - val_loss: 0.6521 - val_accuracy: 0.8683\n","Epoch 16/30\n","637/637 - 165s - loss: 0.0440 - accuracy: 0.9861 - val_loss: 0.6577 - val_accuracy: 0.8732\n","Epoch 17/30\n","637/637 - 165s - loss: 0.0314 - accuracy: 0.9904 - val_loss: 0.6742 - val_accuracy: 0.8780\n","Epoch 18/30\n","637/637 - 165s - loss: 0.0338 - accuracy: 0.9896 - val_loss: 0.6076 - val_accuracy: 0.8634\n","Epoch 19/30\n","637/637 - 165s - loss: 0.0287 - accuracy: 0.9904 - val_loss: 1.1255 - val_accuracy: 0.8634\n","Epoch 20/30\n","637/637 - 165s - loss: 0.0363 - accuracy: 0.9881 - val_loss: 1.6344 - val_accuracy: 0.7073\n","Epoch 21/30\n","637/637 - 165s - loss: 0.0262 - accuracy: 0.9918 - val_loss: 0.4810 - val_accuracy: 0.9171\n","Epoch 22/30\n","637/637 - 165s - loss: 0.0224 - accuracy: 0.9937 - val_loss: 0.5783 - val_accuracy: 0.9024\n","Epoch 23/30\n","637/637 - 165s - loss: 0.0280 - accuracy: 0.9914 - val_loss: 0.6105 - val_accuracy: 0.9073\n","Epoch 24/30\n","637/637 - 165s - loss: 0.0219 - accuracy: 0.9928 - val_loss: 0.6762 - val_accuracy: 0.8683\n","Epoch 25/30\n","637/637 - 165s - loss: 0.0120 - accuracy: 0.9966 - val_loss: 1.1537 - val_accuracy: 0.8439\n","Epoch 26/30\n","637/637 - 165s - loss: 0.0341 - accuracy: 0.9888 - val_loss: 0.9053 - val_accuracy: 0.8683\n","Epoch 27/30\n","637/637 - 165s - loss: 0.0219 - accuracy: 0.9929 - val_loss: 0.8086 - val_accuracy: 0.8683\n","Epoch 28/30\n","637/637 - 165s - loss: 0.0121 - accuracy: 0.9961 - val_loss: 0.5427 - val_accuracy: 0.8829\n","Epoch 29/30\n","637/637 - 165s - loss: 0.0192 - accuracy: 0.9939 - val_loss: 0.5642 - val_accuracy: 0.8927\n","Epoch 30/30\n","637/637 - 165s - loss: 0.0260 - accuracy: 0.9921 - val_loss: 0.7725 - val_accuracy: 0.8683\n","CNN: Epochs=30, Train accuracy=0.99656, Validation accuracy=0.91707\n","XCEPTION + BICUBIC112\n","Epoch 1/30\n","WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0884s vs `on_train_batch_end` time: 0.2898s). Check your callbacks.\n","637/637 - 242s - loss: 0.7627 - accuracy: 0.7393 - val_loss: 0.7266 - val_accuracy: 0.7854\n","Epoch 2/30\n","637/637 - 241s - loss: 0.2575 - accuracy: 0.9134 - val_loss: 0.8592 - val_accuracy: 0.7805\n","Epoch 3/30\n","637/637 - 241s - loss: 0.1434 - accuracy: 0.9511 - val_loss: 2.0147 - val_accuracy: 0.7463\n","Epoch 4/30\n","637/637 - 241s - loss: 0.0973 - accuracy: 0.9670 - val_loss: 0.8002 - val_accuracy: 0.8293\n","Epoch 5/30\n","637/637 - 241s - loss: 0.0722 - accuracy: 0.9761 - val_loss: 1.1881 - val_accuracy: 0.7756\n","Epoch 6/30\n","637/637 - 241s - loss: 0.0614 - accuracy: 0.9801 - val_loss: 0.8498 - val_accuracy: 0.8683\n","Epoch 7/30\n","637/637 - 241s - loss: 0.0469 - accuracy: 0.9844 - val_loss: 0.9105 - val_accuracy: 0.8439\n","Epoch 8/30\n","637/637 - 241s - loss: 0.0467 - accuracy: 0.9844 - val_loss: 0.5382 - val_accuracy: 0.8829\n","Epoch 9/30\n","637/637 - 241s - loss: 0.0357 - accuracy: 0.9884 - val_loss: 0.5815 - val_accuracy: 0.8780\n","Epoch 10/30\n","637/637 - 241s - loss: 0.0374 - accuracy: 0.9886 - val_loss: 0.6290 - val_accuracy: 0.8732\n","Epoch 11/30\n","637/637 - 241s - loss: 0.0369 - accuracy: 0.9887 - val_loss: 0.5585 - val_accuracy: 0.8976\n","Epoch 12/30\n","637/637 - 241s - loss: 0.0258 - accuracy: 0.9914 - val_loss: 0.5709 - val_accuracy: 0.8829\n","Epoch 13/30\n","637/637 - 241s - loss: 0.0331 - accuracy: 0.9905 - val_loss: 0.5844 - val_accuracy: 0.8780\n","Epoch 14/30\n","637/637 - 241s - loss: 0.0167 - accuracy: 0.9951 - val_loss: 0.9695 - val_accuracy: 0.8244\n","Epoch 15/30\n","637/637 - 241s - loss: 0.0320 - accuracy: 0.9903 - val_loss: 0.5691 - val_accuracy: 0.8780\n","Epoch 16/30\n","637/637 - 241s - loss: 0.0203 - accuracy: 0.9935 - val_loss: 1.9155 - val_accuracy: 0.7756\n","Epoch 17/30\n","637/637 - 241s - loss: 0.0277 - accuracy: 0.9915 - val_loss: 1.0376 - val_accuracy: 0.8195\n","Epoch 18/30\n","637/637 - 241s - loss: 0.0184 - accuracy: 0.9945 - val_loss: 0.5570 - val_accuracy: 0.9024\n","Epoch 19/30\n","637/637 - 241s - loss: 0.0121 - accuracy: 0.9965 - val_loss: 0.6279 - val_accuracy: 0.8927\n","Epoch 20/30\n","637/637 - 241s - loss: 0.0293 - accuracy: 0.9911 - val_loss: 1.0740 - val_accuracy: 0.8488\n","Epoch 21/30\n","637/637 - 241s - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.6238 - val_accuracy: 0.8976\n","Epoch 22/30\n","637/637 - 241s - loss: 0.0202 - accuracy: 0.9940 - val_loss: 1.0040 - val_accuracy: 0.8293\n","Epoch 23/30\n","637/637 - 241s - loss: 0.0209 - accuracy: 0.9942 - val_loss: 0.4912 - val_accuracy: 0.8780\n","Epoch 24/30\n","637/637 - 241s - loss: 0.0176 - accuracy: 0.9946 - val_loss: 0.9663 - val_accuracy: 0.8537\n","Epoch 25/30\n","637/637 - 241s - loss: 0.0170 - accuracy: 0.9954 - val_loss: 0.7275 - val_accuracy: 0.8878\n","Epoch 26/30\n","637/637 - 241s - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.6618 - val_accuracy: 0.8732\n","Epoch 27/30\n","637/637 - 241s - loss: 0.0143 - accuracy: 0.9956 - val_loss: 0.6903 - val_accuracy: 0.9024\n","Epoch 28/30\n","637/637 - 241s - loss: 0.0146 - accuracy: 0.9958 - val_loss: 0.6501 - val_accuracy: 0.8829\n","Epoch 29/30\n","637/637 - 241s - loss: 0.0144 - accuracy: 0.9963 - val_loss: 1.3817 - val_accuracy: 0.8146\n","Epoch 30/30\n","637/637 - 241s - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.6691 - val_accuracy: 0.8683\n","CNN: Epochs=30, Train accuracy=0.99887, Validation accuracy=0.90244\n","INCEPTIONRESNETV2 + BICUBIC112\n","Epoch 1/30\n","637/637 - 212s - loss: 0.7483 - accuracy: 0.7493 - val_loss: 1.2695 - val_accuracy: 0.6683\n","Epoch 2/30\n","637/637 - 209s - loss: 0.2444 - accuracy: 0.9197 - val_loss: 0.5715 - val_accuracy: 0.8585\n","Epoch 3/30\n","637/637 - 209s - loss: 0.1433 - accuracy: 0.9520 - val_loss: 0.6629 - val_accuracy: 0.8537\n","Epoch 4/30\n","637/637 - 209s - loss: 0.0984 - accuracy: 0.9682 - val_loss: 0.8430 - val_accuracy: 0.8390\n","Epoch 5/30\n","637/637 - 210s - loss: 0.0751 - accuracy: 0.9762 - val_loss: 0.3646 - val_accuracy: 0.9220\n","Epoch 6/30\n","637/637 - 210s - loss: 0.0679 - accuracy: 0.9782 - val_loss: 1.1049 - val_accuracy: 0.8000\n","Epoch 7/30\n","637/637 - 210s - loss: 0.0606 - accuracy: 0.9821 - val_loss: 0.7631 - val_accuracy: 0.8439\n","Epoch 8/30\n","637/637 - 210s - loss: 0.0582 - accuracy: 0.9822 - val_loss: 0.6421 - val_accuracy: 0.8878\n","Epoch 9/30\n","637/637 - 210s - loss: 0.0356 - accuracy: 0.9881 - val_loss: 0.7087 - val_accuracy: 0.8537\n","Epoch 10/30\n","637/637 - 210s - loss: 0.0430 - accuracy: 0.9866 - val_loss: 0.4206 - val_accuracy: 0.8829\n","Epoch 11/30\n","637/637 - 210s - loss: 0.0305 - accuracy: 0.9904 - val_loss: 0.6659 - val_accuracy: 0.9024\n","Epoch 12/30\n","637/637 - 210s - loss: 0.0408 - accuracy: 0.9882 - val_loss: 0.8433 - val_accuracy: 0.8390\n","Epoch 13/30\n","637/637 - 210s - loss: 0.0320 - accuracy: 0.9894 - val_loss: 0.6943 - val_accuracy: 0.8780\n","Epoch 14/30\n","637/637 - 210s - loss: 0.0221 - accuracy: 0.9928 - val_loss: 0.5644 - val_accuracy: 0.9024\n","Epoch 15/30\n","637/637 - 210s - loss: 0.0271 - accuracy: 0.9916 - val_loss: 1.0399 - val_accuracy: 0.8585\n","Epoch 16/30\n","637/637 - 210s - loss: 0.0275 - accuracy: 0.9921 - val_loss: 0.7468 - val_accuracy: 0.8732\n","Epoch 17/30\n","637/637 - 210s - loss: 0.0229 - accuracy: 0.9936 - val_loss: 0.9882 - val_accuracy: 0.8439\n","Epoch 18/30\n","637/637 - 210s - loss: 0.0101 - accuracy: 0.9971 - val_loss: 0.5887 - val_accuracy: 0.8976\n","Epoch 19/30\n","637/637 - 210s - loss: 0.0262 - accuracy: 0.9919 - val_loss: 0.6094 - val_accuracy: 0.9317\n","Epoch 20/30\n","637/637 - 210s - loss: 0.0277 - accuracy: 0.9917 - val_loss: 0.7057 - val_accuracy: 0.8634\n","Epoch 21/30\n","637/637 - 210s - loss: 0.0160 - accuracy: 0.9956 - val_loss: 1.0203 - val_accuracy: 0.8732\n","Epoch 22/30\n","637/637 - 210s - loss: 0.0169 - accuracy: 0.9955 - val_loss: 0.5840 - val_accuracy: 0.8683\n","Epoch 23/30\n","637/637 - 211s - loss: 0.0224 - accuracy: 0.9937 - val_loss: 0.6915 - val_accuracy: 0.8829\n","Epoch 24/30\n","637/637 - 211s - loss: 0.0160 - accuracy: 0.9954 - val_loss: 0.6109 - val_accuracy: 0.8976\n","Epoch 25/30\n","637/637 - 211s - loss: 0.0117 - accuracy: 0.9973 - val_loss: 0.7353 - val_accuracy: 0.8878\n","Epoch 26/30\n","637/637 - 210s - loss: 0.0192 - accuracy: 0.9940 - val_loss: 0.7630 - val_accuracy: 0.8927\n","Epoch 27/30\n","637/637 - 210s - loss: 0.0186 - accuracy: 0.9955 - val_loss: 0.7306 - val_accuracy: 0.8780\n","Epoch 28/30\n","637/637 - 210s - loss: 0.0081 - accuracy: 0.9978 - val_loss: 0.8722 - val_accuracy: 0.8732\n","Epoch 29/30\n","637/637 - 210s - loss: 0.0114 - accuracy: 0.9968 - val_loss: 0.9536 - val_accuracy: 0.8780\n","Epoch 30/30\n","637/637 - 210s - loss: 0.0216 - accuracy: 0.9940 - val_loss: 0.6255 - val_accuracy: 0.8976\n","CNN: Epochs=30, Train accuracy=0.99779, Validation accuracy=0.93171\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"idEf2q5DMUqu","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m2UXA0_0NqQO","colab_type":"text"},"source":["letter 가 필요한 것인지에 대한 고찰\n","-----------"]},{"cell_type":"code","metadata":{"id":"vAuzfpVVNttk","colab_type":"code","colab":{}},"source":["seed = 0\n","tf.random.set_seed(seed)\n","np.random.seed(seed)\n","\n","ImageGen_coeff = 10\n","epochs_num = 30\n","verbose = 2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5EqAxYF3NuUy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1599225257320,"user_tz":-540,"elapsed":290410,"user":{"displayName":"hidden layer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrHHywJ_Exb4bDD-oZuVoBeLGVG6UVP_5rLMLy=s64","userId":"10845630574575992288"}},"outputId":"4bf8cc3a-fa4e-4475-f37f-83e63e29f500"},"source":["N_dim = 224\n","\n","def normalization(df):\n","    for row in range(len(df)):\n","        maxi = df.iloc[row].max()\n","        mini = df.iloc[row].min()\n","        if maxi == mini:\n","            df.iloc[row] = df.iloc[row].apply(lambda x : 0)\n","        else:\n","            df.iloc[row] = df.iloc[row].apply(lambda x : (x - mini)/(maxi - mini))\n","    x = df.values\n","    if not np.any(x > 1.0) and not np.any(x < 0) and not np.any(np.isnan(x)):\n","        print('Boundary Clear')      \n","    return df\n","\n","def ComputerVision_Dataset():\n","    path = '/content/gdrive/My Drive/Dacon/ComputerVision/train.csv'\n","    path_pixel = '/content/gdrive/My Drive/Dacon/ComputerVision/train_bicubic'+str(N_dim)+'.csv'\n","    train_ratio = 0.9\n","\n","    train = pd.read_csv(path)\n","    train_pixel = pd.read_csv(path_pixel)\n","\n","    point_to = int(len(train) * train_ratio)\n","\n","    train_data = train.iloc[:point_to]\n","    train_data_pixel = train_pixel.iloc[:point_to]\n","    test_data = train.iloc[point_to:]\n","    test_data_pixel = train_pixel.iloc[point_to:]\n","    letter_hash = dict(zip(string.ascii_uppercase, [[1 if i == j else 0 for j in range(26)] for i in range(26)]))\n","\n","    pix = train_data_pixel.iloc[:, 1:]\n","    pix = normalization(pix).values.reshape(-1, N_dim, N_dim, 1)\n","\n","    fix = train_data.iloc[:, 1:3].values\n","\n","    datagenerator = ImageDataGenerator(rotation_range=10, zoom_range=0.10, width_shift_range=0.1,\n","                                       height_shift_range=0.1)\n","    gen = datagenerator.flow(pix, fix, shuffle=False, batch_size=32)\n","    pixel, fixed, batch_index, limit = [], [], 0, 64 * ImageGen_coeff\n","    while batch_index <= limit:\n","        try:\n","            data = gen.next()\n","            pixel += list(data[0])\n","            fixed += list(data[1])\n","            batch_index += 1\n","        except:\n","            print(\"ImageGeneratorError\")\n","            break\n","    fixed_train = np.asarray(fixed)\n","    X_train_pixel = np.asarray(pixel)\n","\n","    Y_train = to_categorical(fixed_train[:, 0], 10)\n","\n","    X_train_label = np.asarray([letter_hash[letter] for letter in fixed_train[:, 1]])\n","\n","    X_valid_pixel = test_data_pixel.iloc[:, 1:]\n","    X_valid_pixel = normalization(X_valid_pixel).values.reshape(-1, N_dim, N_dim, 1)\n","    X_valid_label = np.array([letter_hash[letter] for letter in test_data.iloc[:, 2]])\n","    Y_valid = to_categorical(test_data.iloc[:, 1], 10)\n","\n","    return X_train_label, X_train_pixel, Y_train, X_valid_label, X_valid_pixel, Y_valid\n","\n","\n","X_train_label, X_train_pixel, Y_train, X_valid_label, X_valid_pixel, Y_valid = ComputerVision_Dataset()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Boundary Clear\n","Boundary Clear\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XA4YdSVvNuRE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1599227477568,"user_tz":-540,"elapsed":733007,"user":{"displayName":"hidden layer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrHHywJ_Exb4bDD-oZuVoBeLGVG6UVP_5rLMLy=s64","userId":"10845630574575992288"}},"outputId":"396252bc-b175-494e-9aa5-0960676dcd53"},"source":["def train_test_model(X_train_label, X_train_pixel, Y_train, X_valid_label, X_valid_pixel, Y_valid):\n","    print('RESNET50 + BICUBIC112')\n","    resnet50 = tf.keras.applications.ResNet50(include_top=False, weights=None, input_tensor=None, input_shape=(N_dim,N_dim,1),pooling=None)\n","    cnn_mid = layers.GlobalAveragePooling2D()(resnet50.output)\n","    cnn_out = layers.Dense(128, activation = 'relu')(cnn_mid)\n","    concatenated = layers.Dense(32, activation='relu')(cnn_out)\n","    concat_output = layers.Dense(10, activation='softmax')(concatenated)\n","    concat_model = tf.keras.models.Model(resnet50.input, concat_output)\n","    concat_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","    with tf.device('/device:GPU:0'):\n","        history = concat_model.fit(X_train_pixel, Y_train, epochs=epochs_num,\n","                            validation_data=(X_valid_pixel, Y_valid),\n","                            verbose=verbose)\n","    print(\n","        f\"CNN: Epochs={epochs_num:d}, \" +\n","        f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n","        f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n","    )\n","\n","train_test_model(X_train_label, X_train_pixel, Y_train, X_valid_label, X_valid_pixel, Y_valid)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["RESNET50 + BICUBIC112\n","Epoch 1/30\n","637/637 - 106s - loss: 1.2474 - accuracy: 0.5725 - val_loss: 1.9998 - val_accuracy: 0.5561\n","Epoch 2/30\n","637/637 - 105s - loss: 0.4909 - accuracy: 0.8416 - val_loss: 1.4988 - val_accuracy: 0.6878\n","Epoch 3/30\n","637/637 - 105s - loss: 0.3088 - accuracy: 0.8962 - val_loss: 0.5912 - val_accuracy: 0.8146\n","Epoch 4/30\n","637/637 - 105s - loss: 0.2205 - accuracy: 0.9255 - val_loss: 0.5640 - val_accuracy: 0.8780\n","Epoch 5/30\n","637/637 - 105s - loss: 0.1771 - accuracy: 0.9384 - val_loss: 0.5258 - val_accuracy: 0.8439\n","Epoch 6/30\n","637/637 - 105s - loss: 0.1296 - accuracy: 0.9573 - val_loss: 0.5797 - val_accuracy: 0.8390\n","Epoch 7/30\n","637/637 - 105s - loss: 0.1259 - accuracy: 0.9593 - val_loss: 0.7757 - val_accuracy: 0.8244\n","Epoch 8/30\n","637/637 - 105s - loss: 0.1050 - accuracy: 0.9647 - val_loss: 0.8051 - val_accuracy: 0.8488\n","Epoch 9/30\n","637/637 - 105s - loss: 0.1034 - accuracy: 0.9662 - val_loss: 0.4480 - val_accuracy: 0.8878\n","Epoch 10/30\n","637/637 - 105s - loss: 0.0553 - accuracy: 0.9814 - val_loss: 0.9383 - val_accuracy: 0.8293\n","Epoch 11/30\n","637/637 - 105s - loss: 0.0708 - accuracy: 0.9770 - val_loss: 0.6399 - val_accuracy: 0.8927\n","Epoch 12/30\n","637/637 - 105s - loss: 0.0486 - accuracy: 0.9843 - val_loss: 0.4837 - val_accuracy: 0.8878\n","Epoch 13/30\n","637/637 - 105s - loss: 0.0612 - accuracy: 0.9808 - val_loss: 0.6043 - val_accuracy: 0.8537\n","Epoch 14/30\n","637/637 - 105s - loss: 0.0473 - accuracy: 0.9854 - val_loss: 0.6216 - val_accuracy: 0.8390\n","Epoch 15/30\n","637/637 - 105s - loss: 0.0445 - accuracy: 0.9868 - val_loss: 0.6121 - val_accuracy: 0.8780\n","Epoch 16/30\n","637/637 - 104s - loss: 0.0367 - accuracy: 0.9883 - val_loss: 0.5037 - val_accuracy: 0.8780\n","Epoch 17/30\n","637/637 - 105s - loss: 0.0484 - accuracy: 0.9842 - val_loss: 0.6538 - val_accuracy: 0.8829\n","Epoch 18/30\n","637/637 - 105s - loss: 0.0323 - accuracy: 0.9899 - val_loss: 0.5359 - val_accuracy: 0.8927\n","Epoch 19/30\n","637/637 - 104s - loss: 0.0306 - accuracy: 0.9906 - val_loss: 0.5021 - val_accuracy: 0.8829\n","Epoch 20/30\n","637/637 - 104s - loss: 0.0372 - accuracy: 0.9887 - val_loss: 0.4771 - val_accuracy: 0.8878\n","Epoch 21/30\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-692a6871fb95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     )\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mtrain_test_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_pixel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid_pixel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-6-692a6871fb95>\u001b[0m in \u001b[0;36mtrain_test_model\u001b[0;34m(X_train_label, X_train_pixel, Y_train, X_valid_label, X_valid_pixel, Y_valid)\u001b[0m\n\u001b[1;32m     11\u001b[0m         history = concat_model.fit(X_train_pixel, Y_train, epochs=epochs_num,\n\u001b[1;32m     12\u001b[0m                             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid_pixel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                             verbose=verbose)\n\u001b[0m\u001b[1;32m     14\u001b[0m     print(\n\u001b[1;32m     15\u001b[0m         \u001b[0;34mf\"CNN: Epochs={epochs_num:d}, \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1101\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \"\"\"\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    287\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    307\u001b[0m       \u001b[0mbatch_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    343\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m           \u001b[0mnumpy_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    531\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \"\"\"\n\u001b[1;32m   1062\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"tkdhbVPkNuOO","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eye-glfFCUE4","colab_type":"text"},"source":["letter field 를 one hot encoding 하지 않고 이미지 평균으로 처리하는 방법에 대하여 - 1\n","--------"]},{"cell_type":"code","metadata":{"id":"AuPZZSnICaiS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1599466893530,"user_tz":-540,"elapsed":3899,"user":{"displayName":"hidden layer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrHHywJ_Exb4bDD-oZuVoBeLGVG6UVP_5rLMLy=s64","userId":"10845630574575992288"}},"outputId":"d71ea426-993b-469e-bb79-c32d1fc1234c"},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import sys\n","import math\n","\n","%tensorflow_version 2.x\n","import tensorflow as tf\n","from tensorflow.image import per_image_standardization, resize\n","from tensorflow import keras\n","from tensorflow.keras.utils import to_categorical, Sequence\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras import layers\n","\n","import string\n","\n","path = '/content/gdrive/My Drive/Dacon/ComputerVision/'\n","path_train = path + 'train.csv'\n","path_test = path + 'test.csv'\n","path_submission = path + 'submission.csv'\n","\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","    raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xoIiMZEbCbQ-","colab_type":"code","colab":{}},"source":["seed = 0\n","tf.random.set_seed(seed)\n","np.random.seed(seed)\n","\n","## Global Variables ##\n","train_val_ratio = 0.9\n","ImageGen_coeff = 10\n","N_dim = 224\n","epochs_num = 50\n","verbose = 1\n","batch_size = 32\n","ModelName = 'InceptionResNetV2_224_labelchanged'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JqibEieuCbOk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1599461345828,"user_tz":-540,"elapsed":26998,"user":{"displayName":"hidden layer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrHHywJ_Exb4bDD-oZuVoBeLGVG6UVP_5rLMLy=s64","userId":"10845630574575992288"}},"outputId":"3f4a5705-1542-4548-939d-2fe43ad337c8"},"source":["def conc_and_get_letter_hash_function(train_raw,test_raw):\n","    df = train_raw.iloc[:,2:].append(test_raw.iloc[:,1:], ignore_index = True)\n","    letter_hash = {}\n","    for letter in string.ascii_uppercase:\n","        targ = df[df['letter'] == letter].iloc[1:].mean(axis = 'rows').values.reshape(1,28,28,1)\n","        letter_hash[letter] = per_image_standardization(resize(targ, [N_dim,N_dim], method = tf.image.ResizeMethod.BICUBIC)).numpy().reshape(N_dim,N_dim,1)\n","    return letter_hash\n","\n","def prepare_datasets():\n","    '''\n","    ImageGen_coeff (Global Variable) : number of ImageDataGenerator generation per image\n","    N_dim (Global Variable) : we'll change the size of the image from (28,28) to (N_dim,N_dim)\n","\n","    Since we don't have enough RAM for the resized image of test_pixel, we just return non-resized, non-standardized image.\n","    When we generate each batchs by making use of the tf.utils.Sequential class, we'll resize and standardize test_pixel.\n","    '''\n","    train_raw = pd.read_csv(path_train)\n","    test_raw = pd.read_csv(path_test)\n","\n","    letter_hash = conc_and_get_letter_hash_function(train_raw,test_raw)\n","    letter_hash_func = lambda letter : letter_hash[letter]\n","\n","    ## only for validation \n","    point_to = int(len(train_raw) * train_val_ratio)\n","    train_raw = train_raw.sample(frac=1)\n","    validation_raw = train_raw.iloc[point_to:,:]\n","    train_raw = train_raw.iloc[:point_to,:]\n","    with tf.device('/device:GPU:0'):\n","        validation_pixel = resize(validation_raw.iloc[:,3:].values.astype('int32').reshape(-1,28,28,1), [N_dim,N_dim], method = tf.image.ResizeMethod.BICUBIC)\n","        validation_pixel = per_image_standardization(validation_pixel).numpy()\n","    validation_label = np.asarray(list(map(letter_hash_func, validation_raw.iloc[:,2].values)))\n","    validation_answer = to_categorical(validation_raw.iloc[:,1].values, 10)\n","    ##\n","\n","    pix = train_raw.iloc[:,3:].values.astype('int32').reshape(-1,28,28,1)\n","    fix = train_raw.iloc[:,1:3].values\n","    datagenerator = ImageDataGenerator(rotation_range=10, zoom_range=0.10, width_shift_range=0.1,height_shift_range=0.1)\n","    gen = datagenerator.flow(pix, fix, shuffle=False, batch_size=32)\n","    pixel, fixed, batch_index, limit = [], [], 0, 64 * ImageGen_coeff\n","    while batch_index <= limit:\n","        try:\n","            data = gen.next()\n","            pixel += list(data[0])\n","            fixed += list(data[1])\n","            batch_index += 1\n","        except:\n","            print(\"ImageGeneratorError\")\n","            break\n","    # print(np.asarray(pixel).shape)\n","    with tf.device('/device:GPU:0'):\n","        train_pixel = resize(np.asarray(pixel), [N_dim,N_dim], method = tf.image.ResizeMethod.BICUBIC)\n","        train_pixel = per_image_standardization(train_pixel).numpy()\n","    train_label = np.asarray(list(map(letter_hash_func, np.asarray(fixed)[:,1])))\n","    train_answer = to_categorical(np.asarray(fixed)[:,0], 10)\n","\n","    test_pixel = test_raw.iloc[:,2:].values.astype('int32').reshape(-1,28,28,1)\n","    test_label = np.asarray(list(map(letter_hash_func, test_raw.iloc[:,1].values)))\n","    return train_pixel, train_label, train_answer, test_pixel, test_label, validation_pixel, validation_label, validation_answer\n","\n","train_pixel, train_label, train_answer, test_pixel, test_label, validation_pixel, validation_label, validation_answer = prepare_datasets()\n","print(train_pixel.shape, train_label.shape, train_answer.shape, test_pixel.shape, test_label.shape, validation_pixel.shape, validation_label.shape, validation_answer.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(20369, 224, 224, 1) (20369, 224, 224, 1) (20369, 10) (20480, 28, 28, 1) (20480, 224, 224, 1) (205, 224, 224, 1) (205, 224, 224, 1) (205, 10)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8vaNfBSdCbK5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":887},"executionInfo":{"status":"error","timestamp":1599466097746,"user_tz":-540,"elapsed":4742020,"user":{"displayName":"hidden layer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrHHywJ_Exb4bDD-oZuVoBeLGVG6UVP_5rLMLy=s64","userId":"10845630574575992288"}},"outputId":"c332eedb-fcf6-4b46-c13a-55a49e4c48a4"},"source":["def model(pixel, label, answer, pixel_val, label_val, answer_val):\n","    with tf.device('/device:GPU:0'):\n","        cnn1 = tf.keras.applications.InceptionResNetV2(include_top=False, weights=None, input_tensor=None, input_shape=(N_dim,N_dim,1),pooling=None)\n","        cnn1_mid = layers.GlobalAveragePooling2D()(cnn1.output)\n","        cnn1_out = layers.Dense(256, activation = 'relu')(cnn1_mid)\n","\n","        cnn2 = tf.keras.applications.ResNet50(include_top=False, weights=None, input_tensor=None, input_shape=(N_dim,N_dim,1),pooling=None)\n","        cnn2_mid = layers.GlobalAveragePooling2D()(cnn2.output)\n","        cnn2_out = layers.Dense(256, activation = 'relu')(cnn2_mid)\n","\n","        concatenated = layers.concatenate([cnn1_out, cnn2_out])\n","        concatenated = layers.Dense(256, activation='relu')(concatenated)\n","        concatenated = layers.Dense(128, activation='relu')(concatenated)\n","        concat_output = layers.Dense(10, activation='softmax')(concatenated)\n","        concat_model = tf.keras.models.Model([cnn1.input, cnn2.input], concat_output)\n","        concat_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","        #print(concat_model.summary())\n","        history = concat_model.fit([pixel, label], answer, validation_data=([pixel_val, label_val], answer_val), epochs=epochs_num, verbose=verbose)\n","    concat_model.save(path + ModelName + '.h5')\n","    print(\n","        f\"CNN: Epochs={epochs_num:d}, \" +\n","        f\"Train accuracy={max(history.history['accuracy']):.5f}, \"\n","    )\n","    return concat_model\n","\n","model = model(train_pixel, train_label, train_answer,validation_pixel, validation_label, validation_answer)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","637/637 [==============================] - 326s 512ms/step - loss: 1.5503 - accuracy: 0.4479 - val_loss: 1.2853 - val_accuracy: 0.6439\n","Epoch 2/50\n","637/637 [==============================] - 321s 504ms/step - loss: 0.6712 - accuracy: 0.7759 - val_loss: 0.9112 - val_accuracy: 0.7073\n","Epoch 3/50\n","637/637 [==============================] - 321s 503ms/step - loss: 0.3847 - accuracy: 0.8740 - val_loss: 1.7346 - val_accuracy: 0.6244\n","Epoch 4/50\n","637/637 [==============================] - 321s 504ms/step - loss: 0.2608 - accuracy: 0.9160 - val_loss: 0.7733 - val_accuracy: 0.8341\n","Epoch 5/50\n","637/637 [==============================] - 321s 504ms/step - loss: 0.1860 - accuracy: 0.9395 - val_loss: 1.1367 - val_accuracy: 0.7220\n","Epoch 6/50\n","637/637 [==============================] - 321s 504ms/step - loss: 0.1433 - accuracy: 0.9523 - val_loss: 1.0175 - val_accuracy: 0.7951\n","Epoch 7/50\n","637/637 [==============================] - 321s 504ms/step - loss: 0.1083 - accuracy: 0.9658 - val_loss: 1.3376 - val_accuracy: 0.7463\n","Epoch 8/50\n","637/637 [==============================] - 320s 503ms/step - loss: 0.0971 - accuracy: 0.9689 - val_loss: 1.1126 - val_accuracy: 0.8098\n","Epoch 9/50\n","637/637 [==============================] - 321s 504ms/step - loss: 0.0745 - accuracy: 0.9762 - val_loss: 1.2928 - val_accuracy: 0.7756\n","Epoch 10/50\n","637/637 [==============================] - 320s 503ms/step - loss: 0.0728 - accuracy: 0.9777 - val_loss: 1.0217 - val_accuracy: 0.8049\n","Epoch 11/50\n","637/637 [==============================] - 321s 504ms/step - loss: 0.0578 - accuracy: 0.9825 - val_loss: 1.1550 - val_accuracy: 0.7561\n","Epoch 12/50\n","637/637 [==============================] - 320s 503ms/step - loss: 0.0778 - accuracy: 0.9769 - val_loss: 1.0881 - val_accuracy: 0.8146\n","Epoch 13/50\n","637/637 [==============================] - 321s 503ms/step - loss: 0.0564 - accuracy: 0.9835 - val_loss: 1.1325 - val_accuracy: 0.7902\n","Epoch 14/50\n","637/637 [==============================] - 321s 504ms/step - loss: 0.0414 - accuracy: 0.9874 - val_loss: 1.3095 - val_accuracy: 0.8000\n","Epoch 15/50\n","391/637 [=================>............] - ETA: 2:03 - loss: 0.0469 - accuracy: 0.9874"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-d1c51260266f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcat_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pixel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_answer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_pixel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_answer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-6-d1c51260266f>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(pixel, label, answer, pixel_val, label_val, answer_val)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mconcat_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m#print(concat_model.summary())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpixel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpixel_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mconcat_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mModelName\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     print(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1101\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \"\"\"\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    287\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    307\u001b[0m       \u001b[0mbatch_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    340\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    531\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \"\"\"\n\u001b[1;32m   1062\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"43_N9KzyfF3_","colab_type":"text"},"source":["letter field 를 one hot encoding 하지 않고 이미지 평균으로 처리하는 방법에 대하여 - 2\n","--------"]},{"cell_type":"code","metadata":{"id":"2bWjSJThfM4s","colab_type":"code","colab":{}},"source":["seed = 0\n","tf.random.set_seed(seed)\n","np.random.seed(seed)\n","\n","## Global Variables ##\n","train_val_ratio = 0.9\n","ImageGen_coeff = 10\n","N_dim = 224\n","epochs_num = 50\n","verbose = 1\n","batch_size = 32\n","ModelName = 'InceptionResNetV2_224_labelchanged_2'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"csLDJF90fNBL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1599466938047,"user_tz":-540,"elapsed":25225,"user":{"displayName":"hidden layer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrHHywJ_Exb4bDD-oZuVoBeLGVG6UVP_5rLMLy=s64","userId":"10845630574575992288"}},"outputId":"b06fc173-712e-4096-f4df-db78507d083b"},"source":["def conc_and_get_letter_hash_function(train_raw,test_raw):\n","    df = train_raw.iloc[:,2:].append(test_raw.iloc[:,1:], ignore_index = True)\n","    letter_hash = {}\n","    for letter in string.ascii_uppercase:\n","        targ = df[df['letter'] == letter].iloc[1:].mean(axis = 'rows').values.reshape(1,28,28,1)\n","        letter_hash[letter] = per_image_standardization(resize(targ, [N_dim,N_dim], method = tf.image.ResizeMethod.BICUBIC)).numpy().reshape(N_dim,N_dim,1)\n","    return letter_hash\n","\n","def prepare_datasets():\n","    '''\n","    ImageGen_coeff (Global Variable) : number of ImageDataGenerator generation per image\n","    N_dim (Global Variable) : we'll change the size of the image from (28,28) to (N_dim,N_dim)\n","\n","    Since we don't have enough RAM for the resized image of test_pixel, we just return non-resized, non-standardized image.\n","    When we generate each batchs by making use of the tf.utils.Sequential class, we'll resize and standardize test_pixel.\n","    '''\n","    train_raw = pd.read_csv(path_train)\n","    test_raw = pd.read_csv(path_test)\n","\n","    letter_hash_onehot = dict(zip(string.ascii_uppercase, [[1 if i == j else 0 for j in range(26)] for i in range(26)]))\n","    letter_hash_func_onehot = lambda letter : letter_hash_onehot[letter]\n","\n","    letter_hash = conc_and_get_letter_hash_function(train_raw,test_raw)\n","    letter_hash_func = lambda letter : letter_hash[letter]\n","\n","    ## only for validation \n","    point_to = int(len(train_raw) * train_val_ratio)\n","    train_raw = train_raw.sample(frac=1)\n","    validation_raw = train_raw.iloc[point_to:,:]\n","    train_raw = train_raw.iloc[:point_to,:]\n","    with tf.device('/device:GPU:0'):\n","        validation_pixel = resize(validation_raw.iloc[:,3:].values.astype('int32').reshape(-1,28,28,1), [N_dim,N_dim], method = tf.image.ResizeMethod.BICUBIC)\n","        validation_pixel = per_image_standardization(validation_pixel).numpy()\n","    validation_label = np.asarray(list(map(letter_hash_func, validation_raw.iloc[:,2].values)))\n","    validation_label_onehot = np.asarray(list(map(letter_hash_func_onehot, validation_raw.iloc[:,2].values)))\n","    validation_answer = to_categorical(validation_raw.iloc[:,1].values, 10)\n","    ##\n","\n","    pix = train_raw.iloc[:,3:].values.astype('int32').reshape(-1,28,28,1)\n","    fix = train_raw.iloc[:,1:3].values\n","    datagenerator = ImageDataGenerator(rotation_range=10, zoom_range=0.10, width_shift_range=0.1,height_shift_range=0.1)\n","    gen = datagenerator.flow(pix, fix, shuffle=False, batch_size=32)\n","    pixel, fixed, batch_index, limit = [], [], 0, 64 * ImageGen_coeff\n","    while batch_index <= limit:\n","        try:\n","            data = gen.next()\n","            pixel += list(data[0])\n","            fixed += list(data[1])\n","            batch_index += 1\n","        except:\n","            print(\"ImageGeneratorError\")\n","            break\n","    # print(np.asarray(pixel).shape)\n","    with tf.device('/device:GPU:0'):\n","        train_pixel = resize(np.asarray(pixel), [N_dim,N_dim], method = tf.image.ResizeMethod.BICUBIC)\n","        train_pixel = per_image_standardization(train_pixel).numpy()\n","    train_label = np.asarray(list(map(letter_hash_func, np.asarray(fixed)[:,1])))\n","    train_label_onehot = np.asarray(list(map(letter_hash_func_onehot, np.asarray(fixed)[:,1])))\n","    train_answer = to_categorical(np.asarray(fixed)[:,0], 10)\n","\n","    test_pixel = test_raw.iloc[:,2:].values.astype('int32').reshape(-1,28,28,1)\n","    test_label = np.asarray(list(map(letter_hash_func, test_raw.iloc[:,1].values)))\n","    test_label_onehot = np.asarray(list(map(letter_hash_func_onehot, test_raw.iloc[:,1].values)))\n","    return train_pixel, train_label, train_label_onehot, train_answer, test_pixel, test_label, test_label_onehot, validation_pixel, validation_label, validation_label_onehot, validation_answer\n","\n","train_pixel, train_label, train_label_onehot, train_answer, test_pixel, test_label, test_label_onehot, validation_pixel, validation_label, validation_label_onehot, validation_answer = prepare_datasets()\n","print(train_pixel.shape, train_label.shape, train_label_onehot.shape, train_answer.shape) \n","print(test_pixel.shape, test_label.shape, test_label_onehot.shape)\n","print(validation_pixel.shape, validation_label.shape, validation_label_onehot.shape, validation_answer.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(20369, 224, 224, 1) (20369, 224, 224, 1) (20369, 26) (20369, 10)\n","(20480, 28, 28, 1) (20480, 224, 224, 1) (20480, 26)\n","(205, 224, 224, 1) (205, 224, 224, 1) (205, 26) (205, 10)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SuOjtpOmfTPh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1599476861609,"user_tz":-540,"elapsed":9914222,"user":{"displayName":"hidden layer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrHHywJ_Exb4bDD-oZuVoBeLGVG6UVP_5rLMLy=s64","userId":"10845630574575992288"}},"outputId":"c4240d1d-799d-4821-c379-bbb534233e24"},"source":["def model(pixel, label, label_onehot, answer, pixel_val, label_val, label_val_onehot, answer_val):\n","    with tf.device('/device:GPU:0'):\n","        cnn1 = tf.keras.applications.InceptionResNetV2(include_top=False, weights=None, input_tensor=None, input_shape=(N_dim,N_dim,1),pooling=None)\n","        cnn1_mid = layers.GlobalAveragePooling2D()(cnn1.output)\n","        cnn1_out = layers.Dense(256, activation = 'relu')(cnn1_mid)\n","\n","        cnn2 = tf.keras.applications.ResNet50(include_top=False, weights=None, input_tensor=None, input_shape=(N_dim,N_dim,1),pooling=None)\n","        cnn2_mid = layers.GlobalAveragePooling2D()(cnn2.output)\n","        cnn2_out = layers.Dense(128, activation = 'relu')(cnn2_mid)\n","\n","        dense_input = layers.Input(shape=(26,))\n","        dense_mid = layers.Dense(52, activation = 'relu')(dense_input)\n","        dense_output = layers.Dense(52, activation = 'relu')(dense_mid)\n","\n","        concatenated = layers.concatenate([cnn1_out, cnn2_out, dense_output])\n","        concatenated = layers.Dense(256, activation='relu')(concatenated)\n","        concatenated = layers.Dense(128, activation='relu')(concatenated)\n","        concat_output = layers.Dense(10, activation='softmax')(concatenated)\n","        concat_model = tf.keras.models.Model([cnn1.input, cnn2.input, dense_input], concat_output)\n","        concat_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","        #print(concat_model.summary())\n","        history = concat_model.fit([pixel, label, label_onehot], answer, validation_data=([pixel_val, label_val, label_val_onehot], answer_val), epochs=epochs_num, verbose=verbose)\n","    concat_model.save(path + ModelName + '.h5')\n","    print(\n","        f\"CNN: Epochs={epochs_num:d}, \" +\n","        f\"Train accuracy={max(history.history['accuracy']):.5f}, \"\n","    )\n","    return concat_model\n","\n","model = model(train_pixel, train_label, train_label_onehot, train_answer, validation_pixel, validation_label, validation_label_onehot, validation_answer)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","637/637 [==============================] - 202s 317ms/step - loss: 1.3879 - accuracy: 0.5077 - val_loss: 1.8965 - val_accuracy: 0.4634\n","Epoch 2/50\n","637/637 [==============================] - 197s 309ms/step - loss: 0.5629 - accuracy: 0.8112 - val_loss: 0.7367 - val_accuracy: 0.7756\n","Epoch 3/50\n","637/637 [==============================] - 197s 309ms/step - loss: 0.3117 - accuracy: 0.8977 - val_loss: 0.8582 - val_accuracy: 0.7951\n","Epoch 4/50\n","637/637 [==============================] - 197s 309ms/step - loss: 0.2124 - accuracy: 0.9296 - val_loss: 0.9936 - val_accuracy: 0.7659\n","Epoch 5/50\n","637/637 [==============================] - 197s 309ms/step - loss: 0.1490 - accuracy: 0.9505 - val_loss: 0.7840 - val_accuracy: 0.8341\n","Epoch 6/50\n","637/637 [==============================] - 197s 309ms/step - loss: 0.1132 - accuracy: 0.9632 - val_loss: 1.3560 - val_accuracy: 0.7512\n","Epoch 7/50\n","637/637 [==============================] - 197s 309ms/step - loss: 0.1003 - accuracy: 0.9690 - val_loss: 1.0598 - val_accuracy: 0.7659\n","Epoch 8/50\n","637/637 [==============================] - 197s 309ms/step - loss: 0.0916 - accuracy: 0.9705 - val_loss: 1.1071 - val_accuracy: 0.8195\n","Epoch 9/50\n","637/637 [==============================] - 197s 309ms/step - loss: 0.0685 - accuracy: 0.9774 - val_loss: 8.8338 - val_accuracy: 0.4585\n","Epoch 10/50\n","637/637 [==============================] - 197s 309ms/step - loss: 0.0721 - accuracy: 0.9763 - val_loss: 1.0041 - val_accuracy: 0.8049\n","Epoch 11/50\n","637/637 [==============================] - 197s 309ms/step - loss: 0.0610 - accuracy: 0.9808 - val_loss: 1.0501 - val_accuracy: 0.8049\n","Epoch 12/50\n","637/637 [==============================] - 197s 309ms/step - loss: 0.0529 - accuracy: 0.9837 - val_loss: 1.4156 - val_accuracy: 0.7951\n","Epoch 13/50\n","637/637 [==============================] - 197s 309ms/step - loss: 0.0599 - accuracy: 0.9818 - val_loss: 0.9681 - val_accuracy: 0.8195\n","Epoch 14/50\n","637/637 [==============================] - 197s 309ms/step - loss: 0.0447 - accuracy: 0.9862 - val_loss: 0.9342 - val_accuracy: 0.8439\n","Epoch 15/50\n","637/637 [==============================] - 197s 309ms/step - loss: 0.0481 - accuracy: 0.9859 - val_loss: 1.1027 - val_accuracy: 0.8146\n","Epoch 16/50\n","637/637 [==============================] - 197s 309ms/step - loss: 0.0403 - accuracy: 0.9877 - val_loss: 1.2153 - val_accuracy: 0.8098\n","Epoch 17/50\n","637/637 [==============================] - 197s 309ms/step - loss: 0.0529 - accuracy: 0.9849 - val_loss: 1.2068 - val_accuracy: 0.7756\n","Epoch 18/50\n","637/637 [==============================] - 197s 309ms/step - loss: 0.0265 - accuracy: 0.9918 - val_loss: 1.1515 - val_accuracy: 0.8244\n","Epoch 19/50\n","637/637 [==============================] - 197s 309ms/step - loss: 0.0430 - accuracy: 0.9878 - val_loss: 1.6493 - val_accuracy: 0.7268\n","Epoch 20/50\n","637/637 [==============================] - 197s 309ms/step - loss: 0.0402 - accuracy: 0.9890 - val_loss: 0.8480 - val_accuracy: 0.8439\n","Epoch 21/50\n","637/637 [==============================] - 197s 309ms/step - loss: 0.0247 - accuracy: 0.9933 - val_loss: 0.9730 - val_accuracy: 0.8098\n","Epoch 22/50\n","637/637 [==============================] - 197s 309ms/step - loss: 0.0339 - accuracy: 0.9911 - val_loss: 0.9843 - val_accuracy: 0.8293\n","Epoch 23/50\n","637/637 [==============================] - 197s 309ms/step - loss: 0.0361 - accuracy: 0.9899 - val_loss: 1.1412 - val_accuracy: 0.8195\n","Epoch 24/50\n","637/637 [==============================] - 197s 309ms/step - loss: 0.0230 - accuracy: 0.9933 - val_loss: 1.9018 - val_accuracy: 0.7366\n","Epoch 25/50\n","637/637 [==============================] - 197s 309ms/step - loss: 0.0401 - accuracy: 0.9884 - val_loss: 1.3067 - val_accuracy: 0.8000\n","Epoch 26/50\n","637/637 [==============================] - 197s 309ms/step - loss: 0.0224 - accuracy: 0.9927 - val_loss: 1.7866 - val_accuracy: 0.7659\n","Epoch 27/50\n","637/637 [==============================] - 197s 309ms/step - loss: 0.0235 - accuracy: 0.9933 - val_loss: 0.9857 - val_accuracy: 0.8000\n","Epoch 28/50\n","637/637 [==============================] - 197s 309ms/step - loss: 0.0274 - accuracy: 0.9928 - val_loss: 1.2142 - val_accuracy: 0.8293\n","Epoch 29/50\n","637/637 [==============================] - 197s 309ms/step - loss: 0.0216 - accuracy: 0.9944 - val_loss: 0.9267 - val_accuracy: 0.8683\n","Epoch 30/50\n","637/637 [==============================] - 197s 309ms/step - loss: 0.0306 - accuracy: 0.9921 - val_loss: 1.3155 - val_accuracy: 0.7951\n","Epoch 31/50\n","637/637 [==============================] - 197s 309ms/step - loss: 0.0250 - accuracy: 0.9934 - val_loss: 1.0692 - val_accuracy: 0.8439\n","Epoch 32/50\n","637/637 [==============================] - 197s 310ms/step - loss: 0.0207 - accuracy: 0.9942 - val_loss: 0.9876 - val_accuracy: 0.8293\n","Epoch 33/50\n","637/637 [==============================] - 197s 310ms/step - loss: 0.0215 - accuracy: 0.9940 - val_loss: 1.5362 - val_accuracy: 0.7512\n","Epoch 34/50\n","637/637 [==============================] - 197s 310ms/step - loss: 0.0220 - accuracy: 0.9942 - val_loss: 1.2332 - val_accuracy: 0.7659\n","Epoch 35/50\n","637/637 [==============================] - 197s 310ms/step - loss: 0.0187 - accuracy: 0.9952 - val_loss: 1.3546 - val_accuracy: 0.8049\n","Epoch 36/50\n","637/637 [==============================] - 197s 310ms/step - loss: 0.0277 - accuracy: 0.9929 - val_loss: 1.3988 - val_accuracy: 0.8244\n","Epoch 37/50\n","637/637 [==============================] - 197s 310ms/step - loss: 0.0135 - accuracy: 0.9962 - val_loss: 1.1656 - val_accuracy: 0.8439\n","Epoch 38/50\n","637/637 [==============================] - 197s 310ms/step - loss: 0.0184 - accuracy: 0.9952 - val_loss: 1.3311 - val_accuracy: 0.8146\n","Epoch 39/50\n","637/637 [==============================] - 197s 310ms/step - loss: 0.0190 - accuracy: 0.9950 - val_loss: 1.4442 - val_accuracy: 0.8000\n","Epoch 40/50\n","637/637 [==============================] - 197s 310ms/step - loss: 0.0234 - accuracy: 0.9934 - val_loss: 1.3906 - val_accuracy: 0.8293\n","Epoch 41/50\n","637/637 [==============================] - 197s 309ms/step - loss: 0.0196 - accuracy: 0.9946 - val_loss: 0.9897 - val_accuracy: 0.8390\n","Epoch 42/50\n","637/637 [==============================] - 197s 309ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 1.4402 - val_accuracy: 0.8390\n","Epoch 43/50\n","637/637 [==============================] - 197s 309ms/step - loss: 0.0285 - accuracy: 0.9933 - val_loss: 1.1637 - val_accuracy: 0.8439\n","Epoch 44/50\n","637/637 [==============================] - 197s 309ms/step - loss: 0.0220 - accuracy: 0.9937 - val_loss: 1.4624 - val_accuracy: 0.8244\n","Epoch 45/50\n","637/637 [==============================] - 197s 309ms/step - loss: 0.0159 - accuracy: 0.9962 - val_loss: 1.2836 - val_accuracy: 0.8244\n","Epoch 46/50\n","637/637 [==============================] - 197s 309ms/step - loss: 0.0108 - accuracy: 0.9974 - val_loss: 1.4947 - val_accuracy: 0.8390\n","Epoch 47/50\n","637/637 [==============================] - 197s 309ms/step - loss: 0.0171 - accuracy: 0.9953 - val_loss: 1.0841 - val_accuracy: 0.8488\n","Epoch 48/50\n","637/637 [==============================] - 197s 310ms/step - loss: 0.0132 - accuracy: 0.9972 - val_loss: 1.2420 - val_accuracy: 0.8341\n","Epoch 49/50\n","637/637 [==============================] - 197s 310ms/step - loss: 0.0183 - accuracy: 0.9951 - val_loss: 0.9600 - val_accuracy: 0.8244\n","Epoch 50/50\n","637/637 [==============================] - 197s 310ms/step - loss: 0.0169 - accuracy: 0.9953 - val_loss: 1.4166 - val_accuracy: 0.8341\n","CNN: Epochs=50, Train accuracy=0.99828, \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Iukc7tF5pJLT","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0jczgmCT3yhI","colab_type":"text"},"source":["k-mean 을 이용한 대소문자 구분\n","----------------"]},{"cell_type":"code","metadata":{"id":"8StZ0Ipc31JN","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import sys\n","import math\n","from sklearn.model_selection import train_test_split\n","from sklearn import cluster\n","from skimage import feature\n","%tensorflow_version 2.x\n","import tensorflow as tf\n","from tensorflow.image import resize\n","from tensorflow import keras\n","from tensorflow.keras.utils import to_categorical, Sequence\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras import layers\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","import string\n","\n","path = '/content/gdrive/My Drive/Dacon/ComputerVision/'\n","path_train = path + 'train.csv'\n","path_test = path + 'test.csv'\n","path_submission = path + 'submission.csv'\n","\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","    raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L-vYIE6i31pY","colab_type":"code","colab":{}},"source":["## Global Variables ##\n","ImageGen_coeff = 10\n","N_dim = 224\n","epochs_num = 80\n","verbose = 2\n","batch_size = 32\n","train_val_ratio = 0.9\n","def get_progressbar_str(progress):\n","    MAX_LEN = 30\n","    BAR_LEN = int(MAX_LEN * progress)\n","    return ('Progress:[' + '=' * BAR_LEN +\n","            ('>' if BAR_LEN < MAX_LEN else '') +\n","            ' ' * (MAX_LEN - BAR_LEN) +\n","            '] %.1f%%' % (progress * 100.))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pLgb85i632ED","colab_type":"code","colab":{}},"source":["def image_updown_clustering(df):\n","    for alphabet_large in string.ascii_uppercase:\n","        alphabet_small = alphabet_large.lower()\n","        img_converted = []\n","        images_alphabet = df[df.iloc[:,2] == alphabet_large].iloc[:,3:]\n","        real_idxs = list(images_alphabet.index)\n","        pixels = images_alphabet.values.reshape(-1,28,28)\n","        for pixel in pixels:\n","            img_converted.append(feature.hog(pixel))\n","        k_means = cluster.KMeans(n_clusters = 2)\n","        k_means.fit(np.asarray(img_converted))\n","        for idx, new_label in zip(real_idxs, k_means.labels_):\n","            if new_label == 0:\n","                df.loc[idx,'letter'] = alphabet_small\n","        \n","    return df\n","\n","def prepare_datasets():\n","    '''\n","    ImageGen_coeff (Global Variable) : number of ImageDataGenerator generation per image\n","    N_dim (Global Variable) : we'll change the size of the image from (28,28) to (N_dim,N_dim)\n","\n","    Since we don't have enough RAM for the resized image of test_pixel, we just return non-resized, non-standardized image.\n","    When we generate each batchs by making use of the tf.utils.Sequential class, we'll resize and standardize test_pixel.\n","    '''\n","    train_raw = pd.read_csv(path_train)\n","    train_raw = image_updown_clustering(train_raw)\n","\n","    letter_hash = dict(zip(string.ascii_uppercase + string.ascii_lowercase, [[1 if i == j else 0 for j in range(52)] for i in range(52)]))\n","    letter_hash_func = lambda letter : letter_hash[letter]\n","\n","    ### only for validation \n","    point_to = int(len(train_raw) * train_val_ratio)\n","    train_raw = train_raw.sample(frac=1)\n","    validation_raw = train_raw.iloc[point_to:,:]\n","    train_raw = train_raw.iloc[:point_to,:]\n","    \n","    with tf.device('/device:GPU:0'):\n","        validation_pixel = resize(validation_raw.iloc[:,3:].values.astype('int32').reshape(-1,28,28,1), [N_dim,N_dim], method = tf.image.ResizeMethod.BICUBIC).numpy()\n","    validation_pixel = validation_pixel / 255.0\n","    validation_fix = validation_raw.iloc[:,1:3].values\n","    datagenerator = ImageDataGenerator(rotation_range=10, zoom_range=0.10, width_shift_range=0.1,height_shift_range=0.1)\n","    gen = datagenerator.flow(validation_pixel, validation_fix, shuffle=False, batch_size=32)\n","    pixel, fixed, batch_index, limit = [], [], 0, int((len(validation_pixel) / 32) * ImageGen_coeff)\n","    while batch_index <= limit:\n","        try:\n","            data = gen.next()\n","            pixel += list(data[0])\n","            fixed += list(data[1])\n","            batch_index += 1\n","        except:\n","            print(\"ImageGeneratorError\")\n","            break\n","\n","    validation_pixel = np.asarray(pixel)\n","    validation_label = np.asarray(list(map(letter_hash_func, np.asarray(fixed)[:,1])))\n","    validation_answer = to_categorical(np.asarray(fixed)[:,0], 10)\n","    ###\n","\n","    pix = train_raw.iloc[:,3:].values.astype('int32').reshape(-1,28,28,1)\n","    with tf.device('/device:GPU:0'):\n","        pix = resize(pix, [N_dim,N_dim], method = tf.image.ResizeMethod.BICUBIC).numpy()\n","    pix = pix / 255.0\n","    fix = train_raw.iloc[:,1:3].values\n","    datagenerator = ImageDataGenerator(rotation_range=10, zoom_range=0.10, width_shift_range=0.1,height_shift_range=0.1)\n","    gen = datagenerator.flow(pix, fix, shuffle=False, batch_size=32)\n","    pixel, fixed, batch_index, limit = [], [], 0, int((len(pix) / 32) * ImageGen_coeff)\n","    while batch_index <= limit:\n","        try:\n","            data = gen.next()\n","            pixel += list(data[0])\n","            fixed += list(data[1])\n","            batch_index += 1\n","        except:\n","            print(\"ImageGeneratorError\")\n","            break\n","\n","    train_pixel = np.asarray(pixel)\n","    train_label = np.asarray(list(map(letter_hash_func, np.asarray(fixed)[:,1])))\n","    train_answer = to_categorical(np.asarray(fixed)[:,0], 10)\n","\n","    return train_pixel, train_label, train_answer, validation_pixel, validation_label, validation_answer\n","\n","def prepare_testset():\n","    letter_hash = dict(zip(string.ascii_uppercase + string.ascii_lowercase, [[1 if i == j else 0 for j in range(52)] for i in range(52)]))\n","    letter_hash_func = lambda letter : letter_hash[letter]\n","\n","    test_raw = pd.read_csv(path_test)\n","    test_raw = image_updown_clustering(test_raw)\n","    test_pixel = test_raw.iloc[:,2:].values.astype('int32').reshape(-1,28,28,1)\n","    test_label = np.asarray(list(map(letter_hash_func, test_raw.iloc[:,1].values))).astype('float32')\n","    return test_pixel, test_label\n","\n","test_pixel, test_label = prepare_testset()\n","print(test_pixel.shape, test_label.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JFCuCmOK32Bd","colab_type":"code","colab":{}},"source":["def train_test_model(i):\n","    tf.keras.backend.clear_session()\n","    '''\n","    I shuffled dataset every time since i wanted to get enoughly distributed models.\n","    '''\n","    train_pixel, train_label, train_answer, valid_pixel, valid_label, valid_answer = prepare_datasets()\n","    callbacks1 = [tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy', patience = 15, restore_best_weights = True), ReduceLROnPlateau(monitor = 'loss', patience = 5)]\n","    ModelName = 'InceptionResnetV2_bicubic224_val_kmean'\n","    print(ModelName + '  ' + str(i))\n","    with tf.device('/device:GPU:0'):\n","        cnn = tf.keras.applications.InceptionResNetV2(include_top=False, weights=None, input_tensor=None, input_shape=(N_dim,N_dim,1),pooling=None)\n","        cnn_mid = layers.GlobalAveragePooling2D()(cnn.output)\n","        cnn_out = layers.Dense(128, activation = 'relu')(cnn_mid)\n","\n","        dense_input = layers.Input(shape=(52,))\n","        dense_mid = layers.Dense(104, activation = 'relu')(dense_input)\n","        dense_output = layers.Dense(104, activation = 'relu')(dense_mid)\n","        dense_model = tf.keras.Model(inputs=dense_input, outputs=dense_output)\n","\n","        concatenated = layers.concatenate([cnn_out, dense_model.output])\n","        concatenated = layers.Dense(32, activation='relu')(concatenated)\n","        concat_output = layers.Dense(10, activation='softmax')(concatenated)\n","        concat_model = tf.keras.models.Model([cnn.input, dense_input], concat_output)\n","        concat_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","        history = concat_model.fit([train_pixel, train_label], train_answer, validation_data=([valid_pixel, valid_label], valid_answer), epochs=epochs_num, verbose=verbose, callbacks = callbacks1)\n","    print(\n","        f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n","        f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n","    )\n","    with tf.device('/device:GPU:0'):\n","        concat_model.fit([valid_pixel, valid_label], valid_answer, epochs=5, verbose=verbose)\n","    concat_model.save(path + ModelName + '_' + str(i) + '.h5')\n","\n","for i in range(5):\n","    train_test_model(i)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WOxeA0k_31_F","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pqu4GwXW31mE","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vUWdck1_31jn","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}