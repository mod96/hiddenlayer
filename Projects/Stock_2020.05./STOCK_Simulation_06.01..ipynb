{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"STOCK_Simulation_06.01..ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOC+WsagB8RUh8pr+r2XrYM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"AE9LWGzXTx9I","colab_type":"text"},"source":["# 4.시뮬레이션\n","\n","구간 정해서 시작 전까지 초기train -> 일주일치 시뮬 -> 구간업뎃 -> 일주일치 시뮬 -> ..."]},{"cell_type":"code","metadata":{"id":"xydKNmduTvn8","colab_type":"code","outputId":"97d7d9e5-8137-4339-ea8d-1ae18b8ed594","executionInfo":{"status":"ok","timestamp":1591008100522,"user_tz":-540,"elapsed":4734,"user":{"displayName":"‍한승희[ 학부재학 / 물리학과 ]","photoUrl":"","userId":"03619866707726339561"}},"colab":{"base_uri":"https://localhost:8080/","height":343}},"source":["!nvidia-smi"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Mon Jun  1 10:41:37 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   31C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gc2YIRf6TxtI","colab_type":"code","outputId":"bad9d37c-d601-4a94-9675-46721491aca8","executionInfo":{"status":"ok","timestamp":1591008149113,"user_tz":-540,"elapsed":45543,"user":{"displayName":"‍한승희[ 학부재학 / 물리학과 ]","photoUrl":"","userId":"03619866707726339561"}},"colab":{"base_uri":"https://localhost:8080/","height":182}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive',force_remount=True)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mXNhKLkPTxq9","colab_type":"code","outputId":"b4c8dd1f-85d9-4e4b-d954-ee66dad8ad57","executionInfo":{"status":"error","timestamp":1590909615482,"user_tz":-540,"elapsed":3746,"user":{"displayName":"‍한승희[ 학부재학 / 물리학과 ]","photoUrl":"","userId":"03619866707726339561"}},"colab":{"base_uri":"https://localhost:8080/","height":182}},"source":["#Pretraining, BESTPrediction, PeriodUpdate\n","import pandas as pd\n","import numpy as np\n","%tensorflow_version 2.x\n","import tensorflow as tf\n","from tensorflow.keras import layers, Sequential\n","from datetime import datetime\n","import glob\n","import gc\n","##############################################################################################################################\n","path='/content/gdrive/Shared drives/STOCK/version1/dataset/'\n","save_path='/content/gdrive/Shared drives/STOCK/simulation/models/'\n","trustval_path='/content/gdrive/Shared drives/STOCK/simulation/trustvalue/'\n","available_path='/content/gdrive/Shared drives/STOCK/simulation/available/available.csv'\n","seq_length=50\n","TARGET=2  #0: 종가 1: 시가 2: 고가 3: 저가\n","Today_TARGET=0  #0: 종가 1: 시가 2: 고가 3: 저가  -  내일 TARGET 과 비교해서 수익률을 계산할 오늘의 값\n","fromtime='1996.06.25'\n","##############################################################################################################################Only for Simulation\n","import time\n","SimulationDays=50\n","restdays=int(SimulationDays)\n","seed=1000000\n","UpdatePeriod=14\n","##############################################################################################################################\n","def datapreparation(restdays,KEY_path):\n","    data=pd.read_csv(open(KEY_path, encoding='euc-kr')).iloc[restdays:,:]\n","    data['null']=np.arange(data.shape[0])\n","    data=data.set_index('null')\n","    if int(data.loc[0,'거래량'])==0:          #FaceDivision 처리할 때 index out of range 를 방지하기 위함.\n","        data.loc[0,'거래량']=1\n","    if int(data.loc[data.shape[0]-1,'거래량'])==0:\n","        data.loc[data.shape[0]-1,'거래량']=1\n","    data.drop(['Unnamed: 0','전일비','날짜'],axis=1,inplace=True)\n","    data=data.reindex(index=data.index[::-1])\n","\n","    return data\n","\n","def FaceDivision(df):\n","    if np.isnan(df.to_numpy()).any():\n","        print(\"there exist NaN in raw data\")\n","        print(df[df==np.nan])\n","        raise NotImplementedError\n","    if df.loc[0,'시가']==0:            #거래정지처리\n","      df.loc[0,'시가']=df.loc[0,'종가']\n","    \n","    temp1=pd.DataFrame(df.to_numpy(),columns=df.columns)\n","    temp2=temp1.drop('거래량',axis=1)\n","    index1=list(temp1[temp1['거래량']==0].index) \n","    #비인기주는 아무도 관심을 주지 않아(...) 거래량이 0인 경우도 있다.\n","    #또한 액면분할은 여러번 있을 수 있다.\n","    if len(index1)>1:\n","      idx=[int(i) for i in range(len(index1)-1) if ( index1[i+1]-index1[i] ) > 1 ]\n","      idx.insert(0,-1)\n","      DivisionDays=list(   map(   lambda i:index1[idx[i]+1:idx[i+1]+1] , list(range(len(idx)-1))   )  )\n","      #DivisionDays=[ index1[idx[i]+1:idx[i+1]+1] for i in range(len(idx-1)) ]\n","      DivisionDays.append(index1[idx[-1]+1:])\n","      if len(DivisionDays[0])>0:\n","        for i in range(len(DivisionDays)):\n","            beforeDivision=temp2.loc[DivisionDays[i][0]-1,'종가']\n","            afterDivision=temp2.loc[DivisionDays[i][-1]+1,'시가']\n","            ratio=afterDivision/beforeDivision\n","            if 1/ratio>=1.5:                       #after 에 비해 before 가 1.5 배 이상이면 액면분할이라 가정\n","                temp2.loc[:DivisionDays[i][-1]]=temp2.loc[:DivisionDays[i][-1]]*ratio   #df의 slicing 은 거기까지 포함한다.       \n","\n","    return temp2\n","\n","def Emptyfill(df):            #종가가 모두 존재한다는 가정 하에 시가/고가/저가 항목이 비어있으면 채워준다.\n","    temp=np.array(df.loc[:,'종가'])\n","    temp=np.where(temp==0,np.nan,temp)\n","    assert ~np.isnan(temp).any(), \"there exist 0 in '종가' column\"\n","    \n","    for item in ['시가','고가','저가']:\n","        index1=list(df[df[item].map(int)==0].index)\n","        for each in index1:\n","            df.loc[each,item]=df.loc[each,'종가']\n","    \n","    return df\n","\n","def df2nps(df,seqlen):\n","    seq_len=seqlen+1\n","    temp=df.to_numpy()\n","    result=[ temp[i:i+seq_len,:] for i in range(df.shape[0]-seq_len) ]\n","        \n","    return np.array(result)\n","\n","def normalization_and_split(result,train_ratio,TARGET):\n","    denoms=np.array(list( map(lambda table: [ float(table[0,i]) for i in range(table.shape[1]) ] ,result) ))\n","    for table in result:\n","        for i in range(table.shape[1]):\n","            denominator=float(table[0,i])\n","            table[:,i]=(table[:,i]/denominator)-1\n","\n","    #sklearn 에서 자동으로 섞어주는게 있는데 그것보단 순서 고려해서 쪼개는게 좋은듯\n","    ratio=int(round(len(result)*train_ratio))\n","    train=result[:ratio,:,:]\n","    np.random.shuffle(train)\n","    x_train=train[:,:-1,:]\n","    y_train=train[:,-1,TARGET]\n","    \n","    x_test=result[ratio:,:-1,:]\n","    y_test=result[ratio:,-1,TARGET]\n","    denoms=denoms[ratio:,TARGET]\n","\n","    return x_train, y_train, x_test, y_test, denoms\n","\n","def trustValue(model,x_test,y_test,denoms):\n","    pred = model.predict(x_test)\n","    Ytest=(y_test+1)*denoms\n","    Ypred=(pred.reshape(pred.shape[0])+1)*denoms\n","    Ytest_pct=pd.Series(Ytest).pct_change().dropna()\n","    Ypred_pct=pd.Series(Ypred).pct_change().dropna()\n","    CORR=np.corrcoef(Ytest_pct.values,Ypred_pct.values)\n","\n","    return CORR[0,1]\n","\n","def Prediction(code):\n","    ###########################################################ImportModel\n","    model=tf.keras.models.load_model(save_path+code+'.h5')\n","    ###########################################################ImportTrustValue\n","    f=open(trustval_path+code+'.txt')\n","    T=float(  f.readline()  )\n","    f.close()\n","    ###########################################################\n","    data=Emptyfill( FaceDivision( datapreparation(restdays,path+code+'.csv') ) )\n","    data=data.iloc[data.shape[0]-seq_length:,:].to_numpy()\n","    Today=list(data[-1,:])\n","    temp=list(map(lambda i : float(data[0,i]) , list(range(data.shape[1]))  ) )\n","    for i in range(data.shape[1]):\n","        denominator=float(data[0,i])\n","        data[:,i]=(data[:,i]/denominator)-1\n","    ###########################################################\n","    data=data.reshape((1,seq_length,4))\n","    y=model.predict(data)\n","    TomorrowHigh=(y+1) * temp[TARGET]\n","    r=float(TomorrowHigh-Today[Today_TARGET])/float(Today[Today_TARGET])\n","    #def delete_me(obj):\n","    #    referrers = gc.get_referrers(obj)\n","    #    for referrer in referrers:\n","    #        if type(referrer) == dict:\n","    #            for key, value in referrer.items():\n","    #                if value is obj:\n","    #                    referrer[key] = None\n","    #delete_me(data)\n","    #delete_me(temp)\n","    #gc.collect()\n","    return Today,TomorrowHigh,r,r*T\n","\n","def PeriodDataPreparation(startP,endP,KEY_path):\n","    def dayCal(day):\n","        Y1=int(day[:4])\n","        M1=int(day[5:7])\n","        D1=int(day[8:])\n","        temp1=datetime(Y1,M1,D1)\n","        Y2=int(fromtime[:4])\n","        M2=int(fromtime[5:7])\n","        D2=int(fromtime[8:])\n","        temp2=datetime(Y2,M2,D2)\n","        return (temp1-temp2).days\n","\n","    def PeriodTrue(day):\n","        if day<=dayCal(endP) and day>=dayCal(startP):\n","            return True\n","        else:\n","            return False\n","    data=pd.read_csv(open(KEY_path, encoding='euc-kr'))\n","    index1=data[  data.loc[:,'날짜'].map(dayCal).map(PeriodTrue)  ].index\n","    data=data.iloc[index1[0]:index1[-1]+seq_length,:]  #start 로부터 49개만 더 필요함\n","    data['null']=np.arange(data.shape[0])      #뒤에 코딩할 때 다 loc 으로 해놔서 index 다시 밀어줘야 함...시불...\n","    data=data.set_index('null')\n","    if int(data.loc[0,'거래량'])==0:          #FaceDivision 처리할 때 index out of range 를 방지하기 위함.\n","        data.loc[0,'거래량']=1\n","    if int(data.loc[data.shape[0]-1,'거래량'])==0:\n","        data.loc[data.shape[0]-1,'거래량']=1\n","    data.drop(['Unnamed: 0','전일비','날짜'],axis=1,inplace=True)\n","    data=data.reindex(index=data.index[::-1])\n","\n","    return data\n","\n","def Periodnormalization_and_split(result,TARGET):\n","    for table in result:\n","        for i in range(table.shape[1]):\n","            denominator=float(table[0,i])\n","            table[:,i]=(table[:,i]/denominator)-1\n","    x_test=result[:,:-1,:]\n","    y_test=result[:,-1,TARGET]\n","\n","    return x_test, y_test\n","##############################################################################################################################주요함수들 - 실사용시 restdays=0 넣으면 될듯?\n","#Pretraining : 모든 available.csv 에 대해\n","#BESTPrediction : 모든 model.h5 에 대해\n","#PeriodUpdate  : 모든 model.h5 에 대해\n","def Pretraining(restdays):\n","    KEY_paths=pd.read_csv(open(available_path)).drop('Unnamed: 0',axis=1)\n","    avail=list(KEY_paths.values.reshape((KEY_paths.shape[0])))\n","    fail=[]\n","    with tf.device('/device:GPU:0'):\n","      for KEY_path in KEY_paths.values:\n","        try:\n","          print(\"Processing with index :\",KEY_path[0][-10:-4])\n","          avail.remove(KEY_path[0])\n","          data=datapreparation(restdays,KEY_path[0])\n","          data= FaceDivision(data)\n","          data=Emptyfill(data)\n","          #print(\"Data Length :\",data.shape[0])\n","          result=df2nps( data, seq_length )\n","          x_train, y_train, x_test, y_test, denoms = normalization_and_split(result,0.9,TARGET)\n","\n","          model=Sequential()  #LSTM, adam 이 그나마 나음.\n","          model.add( layers.LSTM(50, return_sequences=True,input_shape=(50,4)) )\n","          model.add( layers.LSTM(64, return_sequences=False))\n","          model.add( layers.Dense(1, activation='linear'))\n","          model.compile(loss='MSE',optimizer='adam')\n","\n","          history=model.fit(x_train,y_train,epochs=10,batch_size=10,verbose=0)   #여기에서 시간이 오래걸림\n","          print('Loss at Epoch 10 :',history.history[ 'loss' ][-1])\n","          if history.history[ 'loss' ][-1]<0.001:\n","            model.fit(x_train,y_train,epochs=10,batch_size=10,verbose=0)\n","            T=trustValue(model,x_test,y_test,denoms)\n","            model.fit(x_test,y_test,epochs=1,batch_size=10,verbose=0)     #신뢰도 구성 후 test 값도 업데이트 해줌.\n","            model.save(save_path+KEY_path[0][-10:-4]+'.h5')\n","            print(\"Correlation Coefficient :\",T,\"\\n\")\n","            f = open(trustval_path+KEY_path[0][-10:-4]+'.txt', \"w\")\n","            f.write(str(T))\n","            f.close()\n","          else:\n","            print('loss is not converging. Pass\\n')\n","        except KeyboardInterrupt:\n","            avail.insert(0,KEY_path[0])\n","            av=pd.Series(avail)\n","            av.to_csv(available_path)\n","            ff=pd.Series(fail)\n","            thistime=datetime.now()\n","            ff.to_csv(available_path[:-13]+'ErrorLog '+str(thistime)+'.csv')\n","            import sys \n","            sys.exit(0)\n","        except:\n","            print('Error')\n","            fail.append(KEY_path[0])\n","            pass\n","    av=pd.Series(avail)\n","    av.to_csv(available_path)\n","    ff=pd.Series(fail)\n","    thistime=datetime.now()\n","    ff.to_csv(available_path[:-13]+'ErrorLog '+str(thistime)+'.csv')\n","    print('ALL MODEL FOR ALL AVAILABLE INDEXES HAS BEEN MADE')\n","\n","def BESTPrediction(restdays):\n","    files=glob.glob(save_path[:-1]+'/*.h5')\n","    codeNtrusted={}\n","    for codepath in files:\n","        try:\n","          code=codepath.replace('\\\\','/')[-9:-3]\n","          #print('processing with code :',code)\n","          with tf.device('/device:GPU:0'):\n","            _,_,_,trusted=Prediction(code)\n","          codeNtrusted.setdefault(trusted,[]).append(code)\n","        except KeyboardInterrupt:\n","            import sys\n","            sys.exit(0)\n","        except:\n","            print('Prediction about index',code,'failed. Pass')\n","            pass\n","    MaximumTrust=max(codeNtrusted.keys())\n","    codes=codeNtrusted[MaximumTrust]\n","\n","    TodayEnd=[] #only for simul\n","    percentages=[]\n","    PredictHigh=[]\n","\n","    for code in codes:\n","        with tf.device('/device:GPU:0'):\n","          Today,TomorrowHigh,r,trusted=Prediction(code)\n","        #print(\"code :\",code,\"Today :\",Today,\"Predicted Tomorrow High :\",int(TomorrowHigh[0]),'Predicted benefit : {}'.format(r*100),'Corr :',trusted/r)\n","        TodayEnd.append(int(Today[0]))\n","        percentages.append(round(r*100,2))\n","        PredictHigh.append(int(TomorrowHigh[0]))\n","    return codes,TodayEnd,percentages,PredictHigh\n","\n","\n","def PeriodUpdate(startP,endP):\n","    files=glob.glob(save_path[:-1]+'/*.h5')\n","    for codepath in files:\n","        try:\n","            code=codepath.replace('\\\\','/')[-9:-3]\n","            #print('processing with code :',code)\n","            data=PeriodDataPreparation(startP,endP,path+code+'.csv')\n","            data=FaceDivision(data)\n","            data=Emptyfill(data)\n","            #print(\"Data Length :\",data.shape[0])\n","            result=df2nps( data, seq_length )\n","            x_test, y_test = Periodnormalization_and_split(result,TARGET)\n","            model=tf.keras.models.load_model(save_path+code+'.h5')\n","            with tf.device('/device:GPU:0'):\n","              model.fit(x_test,y_test,epochs=1,batch_size=1,verbose=0)   #여기에서 시간이 오래걸림\n","            model.save(save_path+code+'.h5')\n","        except KeyboardInterrupt:\n","            import sys\n","            sys.exit(0)\n","        except:\n","            print('Update about index',code,'failed. Pass')\n","            pass\n","    print(\"ALL MODEL UPDATE FOR PERIOD\",startP,\"TO\",endP,\"HAS FINISHED\")\n","##############################################################################################################################\n","if __name__=='__main__': \n","    Pretraining(SimulationDays)\n","    #time.sleep(10)   #구글 드라이브 업데이트가 즉시 되는지 몰라서 일단 넣음\n","    codes=[]\n","    NUM=[]    \n","    Today_temp=[]\n","    for i in range(SimulationDays+1):\n","      Today=pd.read_csv(open(path+'005930.csv', encoding='euc-kr')).iloc[restdays,1]\n","      Today_temp.append(Today)\n","      print('\\n',Today)\n","\n","      if len(codes)>0 and len(NUM)>0:    #SELL\n","        for j in range(len(codes)):\n","          Predicted_Price=PredictHigh[j]\n","          High_Price=pd.read_csv(open(path+codes[j]+'.csv', encoding='euc-kr')).iloc[restdays,5]\n","          End_Price=pd.read_csv(open(path+codes[j]+'.csv', encoding='euc-kr')).iloc[restdays,2]   #종가에 파는 것으로 가정. #0: Unnamed 1: 날짜 2: 종가 3: 변화량 4: 시가 5: 고가 6: 저가 7: 거래량\n","          if Predicted_Price<=High_Price:\n","            Sell_price=Predicted_Price\n","          else:\n","            Sell_price=End_Price\n","          seed+=NUM[j]*Sell_price\n","          print(\"today high :\",High_Price,\" today end :\",End_Price)\n","          print(\"sold\",NUM[j],codes[j],\"at price\",Sell_price)\n","          print(\"restdays :\",restdays,\"seed :\",seed)\n","        codes=[]\n","        NUM=[]\n","\n","      if i<SimulationDays:    #BUY\n","        codes,TodayEnd,percentages,PredictHigh=BESTPrediction(restdays)\n","        for percentage in percentages:\n","          if percentage>2:\n","            l=len(codes)\n","            temp=seed/l\n","            NUM=[]\n","            for j in range(l):\n","              num=int(temp/TodayEnd[j])\n","              NUM.append(num)\n","              seed-=num*TodayEnd[j]\n","              print(\"bought\",num,codes[j],\"at price\",TodayEnd[j],\" predicted tomorrow high :\",PredictHigh[j])\n","          else:\n","             print(\"nothing to buy today\")\n","      \n","      if len(Today_temp)==UpdatePeriod:\n","        PeriodUpdate(Today_temp[0],Today_temp[-1])\n","        Today_temp=[]\n","\n","      restdays-=1\n","      #gc.collect()\n","    print(\"Total gain :\",round((seed-1000000)/1000000,2)*100,\"%\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:241: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:243: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"],"name":"stderr"},{"output_type":"stream","text":["ALL MODEL FOR ALL AVAILABLE INDEXES HAS BEEN MADE\n","\n"," 2020.02.18\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xG7b3AyiHQ9D","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}